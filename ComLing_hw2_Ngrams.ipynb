{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ComLing hw2 Ngrams.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNpGI4J+CEUdSyWG5MUTPG9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snakecharmergh/ComLing/blob/master/ComLing_hw2_Ngrams.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwiZV0Fb69da",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Homework (Task 1)** \n",
        "Implement a trigram language model, generate some texts and compare it to the bigram language model we wrote above. Which one gives better texts?\n",
        "\n",
        "Use the code above as a starting point. You don't really need to change much, but it might be difficult to figure out. Read Jurasky carefully to get a better undestanding. And feel free to ask me any questions.\n",
        "\n",
        "You can use other corpus if you want.\n",
        "\n",
        "Hints:\n",
        "you'll need two start-tags in trigram language model,\n",
        "use bigrams as rows in the matrix and unigrams as columns,\n",
        "if the text you generated is just randow words - something is wrong\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa7e4HTj1V41",
        "colab_type": "code",
        "outputId": "59b6a753-0e14-4375-a1bc-62567ed90f2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from string import punctuation\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdOuC9Up1dhi",
        "colab_type": "code",
        "outputId": "a02ff664-886b-4d7e-8e2b-4e36b79c2bd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "nltk.download('gutenberg')\n",
        "nltk.corpus.gutenberg.fileids()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['austen-emma.txt',\n",
              " 'austen-persuasion.txt',\n",
              " 'austen-sense.txt',\n",
              " 'bible-kjv.txt',\n",
              " 'blake-poems.txt',\n",
              " 'bryant-stories.txt',\n",
              " 'burgess-busterbrown.txt',\n",
              " 'carroll-alice.txt',\n",
              " 'chesterton-ball.txt',\n",
              " 'chesterton-brown.txt',\n",
              " 'chesterton-thursday.txt',\n",
              " 'edgeworth-parents.txt',\n",
              " 'melville-moby_dick.txt',\n",
              " 'milton-paradise.txt',\n",
              " 'shakespeare-caesar.txt',\n",
              " 'shakespeare-hamlet.txt',\n",
              " 'shakespeare-macbeth.txt',\n",
              " 'whitman-leaves.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2KEAHFI6XPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hamlet = nltk.corpus.gutenberg.raw('shakespeare-hamlet.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mW2XPZsK1rc8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(text):\n",
        "    normalized_text = [word.strip(punctuation) for word \\\n",
        "                                                            in text.lower().split()]\n",
        "    normalized_text = [word for word in normalized_text if word]\n",
        "    return normalized_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMkRT0-C71s6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "norm_hamlet = normalize(hamlet)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqlRJ5Wh8u6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_hamlet = Counter(norm_hamlet)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7mB-92h1w23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to get bigram frequencies.\n",
        "def ngrammer(tokens, n=2):\n",
        "    ngrams = []\n",
        "    for i in range(0,len(tokens)-n+1):\n",
        "        ngrams.append(' '.join(tokens[i:i+n]))\n",
        "    return ngrams"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WamgFuC1xpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences_hamlet = [['<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(hamlet)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnpgcDqn2Sv4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unigrams_hamlet = Counter()\n",
        "bigrams_hamlet = Counter()\n",
        "trigrams_hamlet = Counter()\n",
        "\n",
        "for sentence in sentences_hamlet:\n",
        "    unigrams_hamlet.update(sentence)\n",
        "    bigrams_hamlet.update(ngrammer(sentence))\n",
        "    trigrams_hamlet.update(ngrammer(sentence, n=3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGfZiCpKHIMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To create a dictionary of word-index and index-word mapping for the matrix\n",
        "id2word_unigrams = list(unigrams_hamlet)\n",
        "word2id_unigrams = {word:i for i, word in enumerate(id2word_unigrams)}\n",
        "\n",
        "id2word_bigrams = list(bigrams_hamlet)\n",
        "word2id_bigrams = {word:i for i, word in enumerate(id2word_bigrams)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQWFuZAFI621",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matrix_hamlet = np.zeros((len(bigrams_hamlet), \n",
        "                   len(unigrams_hamlet)))\n",
        "\n",
        "for ngram in trigrams_hamlet:\n",
        "    word1, word2, word3 = ngram.split()\n",
        "    bigram = '{} {}'.format(word1, word2)\n",
        "    matrix_hamlet[word2id_bigrams[bigram]][word2id_unigrams[word3]] =  (trigrams_hamlet[ngram]/\n",
        "                                                                                 bigrams_hamlet[bigram])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duhfc8OH4vLD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matrix_hamlet_bigrams = np.zeros((len(unigrams_hamlet), \n",
        "                   len(unigrams_hamlet)))\n",
        "\n",
        "for ngram in bigrams_hamlet:\n",
        "    word1, word2 = ngram.split()\n",
        "    matrix_hamlet_bigrams[word2id_unigrams[word1]][word2id_unigrams[word2]] =  (bigrams_hamlet[ngram]/\n",
        "                                                                     unigrams_hamlet[word1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxx8HGOuEW5M",
        "colab_type": "text"
      },
      "source": [
        "**Bigram-generated text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poXa0fXzFYYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate(matrix, id2word, word2id, n=100, start='<start>'):\n",
        "    text = []\n",
        "    current_idx = word2id[start]\n",
        "    \n",
        "    for i in range(n):\n",
        "        \n",
        "        chosen = np.random.choice(matrix.shape[1], p=matrix[current_idx])\n",
        "        text.append(id2word[chosen])\n",
        "        \n",
        "        if id2word[chosen] == '<end>':\n",
        "            chosen = word2id['<start>']\n",
        "        current_idx = chosen\n",
        "    \n",
        "    return ' '.join(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJCSMSW1OV7A",
        "colab_type": "code",
        "outputId": "f0fc382d-dd25-4135-e1be-24f51018be79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "print(generate(matrix_hamlet_bigrams, id2word_unigrams, word2id_unigrams).replace('<end>', '\\n'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i must render vp the morning know him from a sterrill promontory this but who i am still hast doth burne out of gain-giuing as snow qu \n",
            " neuer beleeue so will fight with this i meane my lord i haue told thee hence pursue me you doe your father in doubt that would harrow vp my sword rebellious hell \n",
            " then i will scarce hold it cannot ham \n",
            " not thinke tis true a winde is my lord i thinke there is that lend a lash that i essentially am i haue thoughts ham \n",
            " ham \n",
            " ham \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzk4S8QqApcB",
        "colab_type": "text"
      },
      "source": [
        "**Trigram-generated text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePFEkELZArnl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def start_step(text, matrix_2, word2id_bigrams, id2word, start_idx):\n",
        "    second_word = np.random.choice(matrix_2.shape[1], p=matrix_2[start_idx])\n",
        "    word = id2word[second_word]\n",
        "    text.append(word)\n",
        "    current_bigram = \"<start> {}\".format(word)\n",
        "    current_idx = word2id_bigrams[current_bigram]\n",
        "    return current_bigram, current_idx\n",
        "\n",
        "def generate(matrix, matrix_2, id2word, word2id_bigrams, word2id_unigrams, n=100):\n",
        "    text = []\n",
        "    start_idx = word2id_unigrams[\"<start>\"]\n",
        "    current_bigram, current_idx = start_step(text, matrix_2, word2id_bigrams, id2word, start_idx)\n",
        "    for i in range(n):\n",
        "\n",
        "        chosen = np.random.choice(matrix.shape[1], p=matrix[current_idx])\n",
        "        word = id2word[chosen]\n",
        "        \n",
        "        if word == '<end>':\n",
        "            current_bigram, current_idx = start_step(text, matrix_2, word2id_bigrams, id2word, start_idx)\n",
        "        else:\n",
        "            text.append(word)\n",
        "            current_bigram = \"{} {}\".format(current_bigram.split()[1], word)\n",
        "            current_idx = word2id_bigrams[current_bigram]\n",
        "    \n",
        "    return ' '.join(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_78ZoS9A4AJ",
        "colab_type": "code",
        "outputId": "4c5ed680-f0a3-4355-f687-4238f6f62811",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(generate(matrix_hamlet, matrix_hamlet_bigrams, id2word_unigrams, word2id_bigrams, word2id_unigrams, n=100).replace('<end>', '\\n'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "exceedingly my lord ham i did verie well my lord begin murderer but orderly to end where i am dead thou liu'st report me and that would be scann'd a villaine dwelling in all i shall liue and feede vpon your maiestie mother you haue heard the cocke crew hor and hath shipped me intill the land and fertile let a beast be lord of beasts and his sandal shoone qu for murther though it make the matter ham for hecuba come let me see another ham euery foole can tell that it is too long but here my father king\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xex4Vo-mT_eB",
        "colab_type": "text"
      },
      "source": [
        "Both bigram and trigram language models generated quite meaningful texts. However, trigram model gives better results because the trigram model looks two words into the past, while the bigram model looks only one word into the past. Thus, the trigram model generated more coherent and comprehensible text. The trigram model somehow generated longer meaningful sentencses like: \"let me see let me be\" or \"a speech of fire that faine would blaze\" or \"she should locke her selfe in ease\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBlWAuNEY8Vb",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Homework (Task 2)**\n",
        "\n",
        "Implement a simple version of Byte-pair-encoding (see first seminar) using gensim.models.Phrases.\n",
        "\n",
        "Apply gensim.models.Phrases to character sequences instead of word sequences (sentences). Train at least 3 Phrases sequentially. As a result you should get whole words or long character ngrams.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAN4jLkeasL2",
        "colab_type": "code",
        "outputId": "9a16f498-d541-4807-c0c8-06ad0ed205f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import re, collections\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import sent_tokenize\n",
        "from nltk import word_tokenize\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "from gensim.models.word2vec import Text8Corpus\n",
        "from gensim.test.utils import datapath"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dFuKfAD2Lsm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = '''Amid the cries of war, death, and poverty, loud sounds deep down of me are rising me up, calling me to find my way out of the rubble, free my own self with the weapon of knowledge and revive my dying country. Armed with hope, I have decided to start my own journey in search for ways to better my life and others’. Bridging the widening gap between Syria and the rest of the world is vital for shaping a better future. Since English speaking countries have a leading role in today’s world and English is the lingua franca, an MA in English Studies is perfect for not only mastering English language but also for getting well-informed about the history, language and culture of such countries.  What can be better than the heart of Europe to be my stop for getting closely in touch with the cultures of those countries?! I found my haven in your prestigious university with its unique MA program to be my final destination for many reasons. First, it is highly acclaimed locally and internationally. Second, the course gives the ability to specialize in linguistics which is interrelated to translation, my PgD. specialization. Furthermore, your academic staff boast international reputation for their professionalism. Moreover, the course is not only fine-tuned to the job market needs but also serves as a springboard into further academic study. It will equip me with up-to-date knowledge, critical perspective, interpretive and analytical skills, argumentative writing, and academic research tools. \n",
        "My undergraduate study of English language and literature enabled me to get more acquainted with both English language and culture. I got a more specialized look into translation, which is a means of knowledge transfer and intercultural communication, through my postgraduate diploma in Translation and Arabization. I am a certified freelance translator. I worked as a translator in the Syrian Parliament and as a translation project manager for Syrian Society for Scientific Research. My hard work paid off when I got the chance to work as a translator in a publishing house in Lebanon and as an interpreter in two conferences under the auspices of the League of Arab States. My attention was not only cast on translation-related jobs, but also on life-changing jobs that will help me in achieving my goals of spreading knowledge and enhancing international relationships. As the IAESTE National Secretary and the Head of Student Exchange in the Syrian Ministry of Higher Education, I could help lots of students to pursue their higher studies and get introduced to different cultures. I am proud I had the chance to participate in strengthening intercultural and educational relations as well as in rebuilding hope and transforming lives of Syrians from being helpless refugees into productive active players in the reconstruction of Syria.\n",
        "Pursuing this program would help realize my goals. First, specializing in linguistics enables me to pursue a career as a translator in an international high profile organization to translate the pains and hopes of the oppressed. I will use translation to get introduced to different fields of knowledge, diverse cultures and the latest developments. This contributes to the reconstruction of Syria. Furthermore, English Studies is vital for finding out points of convergence between Arabs and the rest of the world, correcting misconceptions, and defying stereotypes. It would serve as a springboard for openness and acceptance of the “Other”. It will hopefully contribute to turning the world into a more harmonious, well-informed and secure place to live in. \n",
        "In short, my proven abilities would make me a perfect fit. My ambition to further develop myself and my thirst for employing the things I learn in helping others especially Syrians in times of war and later on in rebuilding Syria is the strongest motivation to keep me working relentlessly. This makes me meet the standards of your prestigious institution.'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZaHnRM51nbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = sent_tokenize(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dYjoIJN1y9O",
        "colab_type": "code",
        "outputId": "f66fa4ef-b3fb-4b13-9fcf-860b0accbc53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        }
      },
      "source": [
        "sentences"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Amid the cries of war, death, and poverty, loud sounds deep down of me are rising me up, calling me to find my way out of the rubble, free my own self with the weapon of knowledge and revive my dying country.',\n",
              " 'Armed with hope, I have decided to start my own journey in search for ways to better my life and others’.',\n",
              " 'Bridging the widening gap between Syria and the rest of the world is vital for shaping a better future.',\n",
              " 'Since English speaking countries have a leading role in today’s world and English is the lingua franca, an MA in English Studies is perfect for not only mastering English language but also for getting well-informed about the history, language and culture of such countries.',\n",
              " 'What can be better than the heart of Europe to be my stop for getting closely in touch with the cultures of those countries?!',\n",
              " 'I found my haven in your prestigious university with its unique MA program to be my final destination for many reasons.',\n",
              " 'First, it is highly acclaimed locally and internationally.',\n",
              " 'Second, the course gives the ability to specialize in linguistics which is interrelated to translation, my PgD.',\n",
              " 'specialization.',\n",
              " 'Furthermore, your academic staff boast international reputation for their professionalism.',\n",
              " 'Moreover, the course is not only fine-tuned to the job market needs but also serves as a springboard into further academic study.',\n",
              " 'It will equip me with up-to-date knowledge, critical perspective, interpretive and analytical skills, argumentative writing, and academic research tools.',\n",
              " 'My undergraduate study of English language and literature enabled me to get more acquainted with both English language and culture.',\n",
              " 'I got a more specialized look into translation, which is a means of knowledge transfer and intercultural communication, through my postgraduate diploma in Translation and Arabization.',\n",
              " 'I am a certified freelance translator.',\n",
              " 'I worked as a translator in the Syrian Parliament and as a translation project manager for Syrian Society for Scientific Research.',\n",
              " 'My hard work paid off when I got the chance to work as a translator in a publishing house in Lebanon and as an interpreter in two conferences under the auspices of the League of Arab States.',\n",
              " 'My attention was not only cast on translation-related jobs, but also on life-changing jobs that will help me in achieving my goals of spreading knowledge and enhancing international relationships.',\n",
              " 'As the IAESTE National Secretary and the Head of Student Exchange in the Syrian Ministry of Higher Education, I could help lots of students to pursue their higher studies and get introduced to different cultures.',\n",
              " 'I am proud I had the chance to participate in strengthening intercultural and educational relations as well as in rebuilding hope and transforming lives of Syrians from being helpless refugees into productive active players in the reconstruction of Syria.',\n",
              " 'Pursuing this program would help realize my goals.',\n",
              " 'First, specializing in linguistics enables me to pursue a career as a translator in an international high profile organization to translate the pains and hopes of the oppressed.',\n",
              " 'I will use translation to get introduced to different fields of knowledge, diverse cultures and the latest developments.',\n",
              " 'This contributes to the reconstruction of Syria.',\n",
              " 'Furthermore, English Studies is vital for finding out points of convergence between Arabs and the rest of the world, correcting misconceptions, and defying stereotypes.',\n",
              " 'It would serve as a springboard for openness and acceptance of the “Other”.',\n",
              " 'It will hopefully contribute to turning the world into a more harmonious, well-informed and secure place to live in.',\n",
              " 'In short, my proven abilities would make me a perfect fit.',\n",
              " 'My ambition to further develop myself and my thirst for employing the things I learn in helping others especially Syrians in times of war and later on in rebuilding Syria is the strongest motivation to keep me working relentlessly.',\n",
              " 'This makes me meet the standards of your prestigious institution.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDXt4-0f2Bou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split(word): \n",
        "    return [char for char in word]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6n2SKhBY2ilD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = []\n",
        "for i in range(len(sentences)):\n",
        "    vocab.append(split(sentences[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jpyg3sgU2783",
        "colab_type": "code",
        "outputId": "08a2bf94-a6e5-4807-e79a-9b555eb147d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['A', 'm', 'i', 'd', ' ', 't', 'h', 'e', ' ', 'c', 'r', 'i', 'e', 's', ' ', 'o', 'f', ' ', 'w', 'a', 'r', ',', ' ', 'd', 'e', 'a', 't', 'h', ',', ' ', 'a', 'n', 'd', ' ', 'p', 'o', 'v', 'e', 'r', 't', 'y', ',', ' ', 'l', 'o', 'u', 'd', ' ', 's', 'o', 'u', 'n', 'd', 's', ' ', 'd', 'e', 'e', 'p', ' ', 'd', 'o', 'w', 'n', ' ', 'o', 'f', ' ', 'm', 'e', ' ', 'a', 'r', 'e', ' ', 'r', 'i', 's', 'i', 'n', 'g', ' ', 'm', 'e', ' ', 'u', 'p', ',', ' ', 'c', 'a', 'l', 'l', 'i', 'n', 'g', ' ', 'm', 'e', ' ', 't', 'o', ' ', 'f', 'i', 'n', 'd', ' ', 'm', 'y', ' ', 'w', 'a', 'y', ' ', 'o', 'u', 't', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 'r', 'u', 'b', 'b', 'l', 'e', ',', ' ', 'f', 'r', 'e', 'e', ' ', 'm', 'y', ' ', 'o', 'w', 'n', ' ', 's', 'e', 'l', 'f', ' ', 'w', 'i', 't', 'h', ' ', 't', 'h', 'e', ' ', 'w', 'e', 'a', 'p', 'o', 'n', ' ', 'o', 'f', ' ', 'k', 'n', 'o', 'w', 'l', 'e', 'd', 'g', 'e', ' ', 'a', 'n', 'd', ' ', 'r', 'e', 'v', 'i', 'v', 'e', ' ', 'm', 'y', ' ', 'd', 'y', 'i', 'n', 'g', ' ', 'c', 'o', 'u', 'n', 't', 'r', 'y', '.'], ['A', 'r', 'm', 'e', 'd', ' ', 'w', 'i', 't', 'h', ' ', 'h', 'o', 'p', 'e', ',', ' ', 'I', ' ', 'h', 'a', 'v', 'e', ' ', 'd', 'e', 'c', 'i', 'd', 'e', 'd', ' ', 't', 'o', ' ', 's', 't', 'a', 'r', 't', ' ', 'm', 'y', ' ', 'o', 'w', 'n', ' ', 'j', 'o', 'u', 'r', 'n', 'e', 'y', ' ', 'i', 'n', ' ', 's', 'e', 'a', 'r', 'c', 'h', ' ', 'f', 'o', 'r', ' ', 'w', 'a', 'y', 's', ' ', 't', 'o', ' ', 'b', 'e', 't', 't', 'e', 'r', ' ', 'm', 'y', ' ', 'l', 'i', 'f', 'e', ' ', 'a', 'n', 'd', ' ', 'o', 't', 'h', 'e', 'r', 's', '’', '.'], ['B', 'r', 'i', 'd', 'g', 'i', 'n', 'g', ' ', 't', 'h', 'e', ' ', 'w', 'i', 'd', 'e', 'n', 'i', 'n', 'g', ' ', 'g', 'a', 'p', ' ', 'b', 'e', 't', 'w', 'e', 'e', 'n', ' ', 'S', 'y', 'r', 'i', 'a', ' ', 'a', 'n', 'd', ' ', 't', 'h', 'e', ' ', 'r', 'e', 's', 't', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 'w', 'o', 'r', 'l', 'd', ' ', 'i', 's', ' ', 'v', 'i', 't', 'a', 'l', ' ', 'f', 'o', 'r', ' ', 's', 'h', 'a', 'p', 'i', 'n', 'g', ' ', 'a', ' ', 'b', 'e', 't', 't', 'e', 'r', ' ', 'f', 'u', 't', 'u', 'r', 'e', '.'], ['S', 'i', 'n', 'c', 'e', ' ', 'E', 'n', 'g', 'l', 'i', 's', 'h', ' ', 's', 'p', 'e', 'a', 'k', 'i', 'n', 'g', ' ', 'c', 'o', 'u', 'n', 't', 'r', 'i', 'e', 's', ' ', 'h', 'a', 'v', 'e', ' ', 'a', ' ', 'l', 'e', 'a', 'd', 'i', 'n', 'g', ' ', 'r', 'o', 'l', 'e', ' ', 'i', 'n', ' ', 't', 'o', 'd', 'a', 'y', '’', 's', ' ', 'w', 'o', 'r', 'l', 'd', ' ', 'a', 'n', 'd', ' ', 'E', 'n', 'g', 'l', 'i', 's', 'h', ' ', 'i', 's', ' ', 't', 'h', 'e', ' ', 'l', 'i', 'n', 'g', 'u', 'a', ' ', 'f', 'r', 'a', 'n', 'c', 'a', ',', ' ', 'a', 'n', ' ', 'M', 'A', ' ', 'i', 'n', ' ', 'E', 'n', 'g', 'l', 'i', 's', 'h', ' ', 'S', 't', 'u', 'd', 'i', 'e', 's', ' ', 'i', 's', ' ', 'p', 'e', 'r', 'f', 'e', 'c', 't', ' ', 'f', 'o', 'r', ' ', 'n', 'o', 't', ' ', 'o', 'n', 'l', 'y', ' ', 'm', 'a', 's', 't', 'e', 'r', 'i', 'n', 'g', ' ', 'E', 'n', 'g', 'l', 'i', 's', 'h', ' ', 'l', 'a', 'n', 'g', 'u', 'a', 'g', 'e', ' ', 'b', 'u', 't', ' ', 'a', 'l', 's', 'o', ' ', 'f', 'o', 'r', ' ', 'g', 'e', 't', 't', 'i', 'n', 'g', ' ', 'w', 'e', 'l', 'l', '-', 'i', 'n', 'f', 'o', 'r', 'm', 'e', 'd', ' ', 'a', 'b', 'o', 'u', 't', ' ', 't', 'h', 'e', ' ', 'h', 'i', 's', 't', 'o', 'r', 'y', ',', ' ', 'l', 'a', 'n', 'g', 'u', 'a', 'g', 'e', ' ', 'a', 'n', 'd', ' ', 'c', 'u', 'l', 't', 'u', 'r', 'e', ' ', 'o', 'f', ' ', 's', 'u', 'c', 'h', ' ', 'c', 'o', 'u', 'n', 't', 'r', 'i', 'e', 's', '.'], ['W', 'h', 'a', 't', ' ', 'c', 'a', 'n', ' ', 'b', 'e', ' ', 'b', 'e', 't', 't', 'e', 'r', ' ', 't', 'h', 'a', 'n', ' ', 't', 'h', 'e', ' ', 'h', 'e', 'a', 'r', 't', ' ', 'o', 'f', ' ', 'E', 'u', 'r', 'o', 'p', 'e', ' ', 't', 'o', ' ', 'b', 'e', ' ', 'm', 'y', ' ', 's', 't', 'o', 'p', ' ', 'f', 'o', 'r', ' ', 'g', 'e', 't', 't', 'i', 'n', 'g', ' ', 'c', 'l', 'o', 's', 'e', 'l', 'y', ' ', 'i', 'n', ' ', 't', 'o', 'u', 'c', 'h', ' ', 'w', 'i', 't', 'h', ' ', 't', 'h', 'e', ' ', 'c', 'u', 'l', 't', 'u', 'r', 'e', 's', ' ', 'o', 'f', ' ', 't', 'h', 'o', 's', 'e', ' ', 'c', 'o', 'u', 'n', 't', 'r', 'i', 'e', 's', '?', '!'], ['I', ' ', 'f', 'o', 'u', 'n', 'd', ' ', 'm', 'y', ' ', 'h', 'a', 'v', 'e', 'n', ' ', 'i', 'n', ' ', 'y', 'o', 'u', 'r', ' ', 'p', 'r', 'e', 's', 't', 'i', 'g', 'i', 'o', 'u', 's', ' ', 'u', 'n', 'i', 'v', 'e', 'r', 's', 'i', 't', 'y', ' ', 'w', 'i', 't', 'h', ' ', 'i', 't', 's', ' ', 'u', 'n', 'i', 'q', 'u', 'e', ' ', 'M', 'A', ' ', 'p', 'r', 'o', 'g', 'r', 'a', 'm', ' ', 't', 'o', ' ', 'b', 'e', ' ', 'm', 'y', ' ', 'f', 'i', 'n', 'a', 'l', ' ', 'd', 'e', 's', 't', 'i', 'n', 'a', 't', 'i', 'o', 'n', ' ', 'f', 'o', 'r', ' ', 'm', 'a', 'n', 'y', ' ', 'r', 'e', 'a', 's', 'o', 'n', 's', '.'], ['F', 'i', 'r', 's', 't', ',', ' ', 'i', 't', ' ', 'i', 's', ' ', 'h', 'i', 'g', 'h', 'l', 'y', ' ', 'a', 'c', 'c', 'l', 'a', 'i', 'm', 'e', 'd', ' ', 'l', 'o', 'c', 'a', 'l', 'l', 'y', ' ', 'a', 'n', 'd', ' ', 'i', 'n', 't', 'e', 'r', 'n', 'a', 't', 'i', 'o', 'n', 'a', 'l', 'l', 'y', '.'], ['S', 'e', 'c', 'o', 'n', 'd', ',', ' ', 't', 'h', 'e', ' ', 'c', 'o', 'u', 'r', 's', 'e', ' ', 'g', 'i', 'v', 'e', 's', ' ', 't', 'h', 'e', ' ', 'a', 'b', 'i', 'l', 'i', 't', 'y', ' ', 't', 'o', ' ', 's', 'p', 'e', 'c', 'i', 'a', 'l', 'i', 'z', 'e', ' ', 'i', 'n', ' ', 'l', 'i', 'n', 'g', 'u', 'i', 's', 't', 'i', 'c', 's', ' ', 'w', 'h', 'i', 'c', 'h', ' ', 'i', 's', ' ', 'i', 'n', 't', 'e', 'r', 'r', 'e', 'l', 'a', 't', 'e', 'd', ' ', 't', 'o', ' ', 't', 'r', 'a', 'n', 's', 'l', 'a', 't', 'i', 'o', 'n', ',', ' ', 'm', 'y', ' ', 'P', 'g', 'D', '.'], ['s', 'p', 'e', 'c', 'i', 'a', 'l', 'i', 'z', 'a', 't', 'i', 'o', 'n', '.'], ['F', 'u', 'r', 't', 'h', 'e', 'r', 'm', 'o', 'r', 'e', ',', ' ', 'y', 'o', 'u', 'r', ' ', 'a', 'c', 'a', 'd', 'e', 'm', 'i', 'c', ' ', 's', 't', 'a', 'f', 'f', ' ', 'b', 'o', 'a', 's', 't', ' ', 'i', 'n', 't', 'e', 'r', 'n', 'a', 't', 'i', 'o', 'n', 'a', 'l', ' ', 'r', 'e', 'p', 'u', 't', 'a', 't', 'i', 'o', 'n', ' ', 'f', 'o', 'r', ' ', 't', 'h', 'e', 'i', 'r', ' ', 'p', 'r', 'o', 'f', 'e', 's', 's', 'i', 'o', 'n', 'a', 'l', 'i', 's', 'm', '.'], ['M', 'o', 'r', 'e', 'o', 'v', 'e', 'r', ',', ' ', 't', 'h', 'e', ' ', 'c', 'o', 'u', 'r', 's', 'e', ' ', 'i', 's', ' ', 'n', 'o', 't', ' ', 'o', 'n', 'l', 'y', ' ', 'f', 'i', 'n', 'e', '-', 't', 'u', 'n', 'e', 'd', ' ', 't', 'o', ' ', 't', 'h', 'e', ' ', 'j', 'o', 'b', ' ', 'm', 'a', 'r', 'k', 'e', 't', ' ', 'n', 'e', 'e', 'd', 's', ' ', 'b', 'u', 't', ' ', 'a', 'l', 's', 'o', ' ', 's', 'e', 'r', 'v', 'e', 's', ' ', 'a', 's', ' ', 'a', ' ', 's', 'p', 'r', 'i', 'n', 'g', 'b', 'o', 'a', 'r', 'd', ' ', 'i', 'n', 't', 'o', ' ', 'f', 'u', 'r', 't', 'h', 'e', 'r', ' ', 'a', 'c', 'a', 'd', 'e', 'm', 'i', 'c', ' ', 's', 't', 'u', 'd', 'y', '.'], ['I', 't', ' ', 'w', 'i', 'l', 'l', ' ', 'e', 'q', 'u', 'i', 'p', ' ', 'm', 'e', ' ', 'w', 'i', 't', 'h', ' ', 'u', 'p', '-', 't', 'o', '-', 'd', 'a', 't', 'e', ' ', 'k', 'n', 'o', 'w', 'l', 'e', 'd', 'g', 'e', ',', ' ', 'c', 'r', 'i', 't', 'i', 'c', 'a', 'l', ' ', 'p', 'e', 'r', 's', 'p', 'e', 'c', 't', 'i', 'v', 'e', ',', ' ', 'i', 'n', 't', 'e', 'r', 'p', 'r', 'e', 't', 'i', 'v', 'e', ' ', 'a', 'n', 'd', ' ', 'a', 'n', 'a', 'l', 'y', 't', 'i', 'c', 'a', 'l', ' ', 's', 'k', 'i', 'l', 'l', 's', ',', ' ', 'a', 'r', 'g', 'u', 'm', 'e', 'n', 't', 'a', 't', 'i', 'v', 'e', ' ', 'w', 'r', 'i', 't', 'i', 'n', 'g', ',', ' ', 'a', 'n', 'd', ' ', 'a', 'c', 'a', 'd', 'e', 'm', 'i', 'c', ' ', 'r', 'e', 's', 'e', 'a', 'r', 'c', 'h', ' ', 't', 'o', 'o', 'l', 's', '.'], ['M', 'y', ' ', 'u', 'n', 'd', 'e', 'r', 'g', 'r', 'a', 'd', 'u', 'a', 't', 'e', ' ', 's', 't', 'u', 'd', 'y', ' ', 'o', 'f', ' ', 'E', 'n', 'g', 'l', 'i', 's', 'h', ' ', 'l', 'a', 'n', 'g', 'u', 'a', 'g', 'e', ' ', 'a', 'n', 'd', ' ', 'l', 'i', 't', 'e', 'r', 'a', 't', 'u', 'r', 'e', ' ', 'e', 'n', 'a', 'b', 'l', 'e', 'd', ' ', 'm', 'e', ' ', 't', 'o', ' ', 'g', 'e', 't', ' ', 'm', 'o', 'r', 'e', ' ', 'a', 'c', 'q', 'u', 'a', 'i', 'n', 't', 'e', 'd', ' ', 'w', 'i', 't', 'h', ' ', 'b', 'o', 't', 'h', ' ', 'E', 'n', 'g', 'l', 'i', 's', 'h', ' ', 'l', 'a', 'n', 'g', 'u', 'a', 'g', 'e', ' ', 'a', 'n', 'd', ' ', 'c', 'u', 'l', 't', 'u', 'r', 'e', '.'], ['I', ' ', 'g', 'o', 't', ' ', 'a', ' ', 'm', 'o', 'r', 'e', ' ', 's', 'p', 'e', 'c', 'i', 'a', 'l', 'i', 'z', 'e', 'd', ' ', 'l', 'o', 'o', 'k', ' ', 'i', 'n', 't', 'o', ' ', 't', 'r', 'a', 'n', 's', 'l', 'a', 't', 'i', 'o', 'n', ',', ' ', 'w', 'h', 'i', 'c', 'h', ' ', 'i', 's', ' ', 'a', ' ', 'm', 'e', 'a', 'n', 's', ' ', 'o', 'f', ' ', 'k', 'n', 'o', 'w', 'l', 'e', 'd', 'g', 'e', ' ', 't', 'r', 'a', 'n', 's', 'f', 'e', 'r', ' ', 'a', 'n', 'd', ' ', 'i', 'n', 't', 'e', 'r', 'c', 'u', 'l', 't', 'u', 'r', 'a', 'l', ' ', 'c', 'o', 'm', 'm', 'u', 'n', 'i', 'c', 'a', 't', 'i', 'o', 'n', ',', ' ', 't', 'h', 'r', 'o', 'u', 'g', 'h', ' ', 'm', 'y', ' ', 'p', 'o', 's', 't', 'g', 'r', 'a', 'd', 'u', 'a', 't', 'e', ' ', 'd', 'i', 'p', 'l', 'o', 'm', 'a', ' ', 'i', 'n', ' ', 'T', 'r', 'a', 'n', 's', 'l', 'a', 't', 'i', 'o', 'n', ' ', 'a', 'n', 'd', ' ', 'A', 'r', 'a', 'b', 'i', 'z', 'a', 't', 'i', 'o', 'n', '.'], ['I', ' ', 'a', 'm', ' ', 'a', ' ', 'c', 'e', 'r', 't', 'i', 'f', 'i', 'e', 'd', ' ', 'f', 'r', 'e', 'e', 'l', 'a', 'n', 'c', 'e', ' ', 't', 'r', 'a', 'n', 's', 'l', 'a', 't', 'o', 'r', '.'], ['I', ' ', 'w', 'o', 'r', 'k', 'e', 'd', ' ', 'a', 's', ' ', 'a', ' ', 't', 'r', 'a', 'n', 's', 'l', 'a', 't', 'o', 'r', ' ', 'i', 'n', ' ', 't', 'h', 'e', ' ', 'S', 'y', 'r', 'i', 'a', 'n', ' ', 'P', 'a', 'r', 'l', 'i', 'a', 'm', 'e', 'n', 't', ' ', 'a', 'n', 'd', ' ', 'a', 's', ' ', 'a', ' ', 't', 'r', 'a', 'n', 's', 'l', 'a', 't', 'i', 'o', 'n', ' ', 'p', 'r', 'o', 'j', 'e', 'c', 't', ' ', 'm', 'a', 'n', 'a', 'g', 'e', 'r', ' ', 'f', 'o', 'r', ' ', 'S', 'y', 'r', 'i', 'a', 'n', ' ', 'S', 'o', 'c', 'i', 'e', 't', 'y', ' ', 'f', 'o', 'r', ' ', 'S', 'c', 'i', 'e', 'n', 't', 'i', 'f', 'i', 'c', ' ', 'R', 'e', 's', 'e', 'a', 'r', 'c', 'h', '.'], ['M', 'y', ' ', 'h', 'a', 'r', 'd', ' ', 'w', 'o', 'r', 'k', ' ', 'p', 'a', 'i', 'd', ' ', 'o', 'f', 'f', ' ', 'w', 'h', 'e', 'n', ' ', 'I', ' ', 'g', 'o', 't', ' ', 't', 'h', 'e', ' ', 'c', 'h', 'a', 'n', 'c', 'e', ' ', 't', 'o', ' ', 'w', 'o', 'r', 'k', ' ', 'a', 's', ' ', 'a', ' ', 't', 'r', 'a', 'n', 's', 'l', 'a', 't', 'o', 'r', ' ', 'i', 'n', ' ', 'a', ' ', 'p', 'u', 'b', 'l', 'i', 's', 'h', 'i', 'n', 'g', ' ', 'h', 'o', 'u', 's', 'e', ' ', 'i', 'n', ' ', 'L', 'e', 'b', 'a', 'n', 'o', 'n', ' ', 'a', 'n', 'd', ' ', 'a', 's', ' ', 'a', 'n', ' ', 'i', 'n', 't', 'e', 'r', 'p', 'r', 'e', 't', 'e', 'r', ' ', 'i', 'n', ' ', 't', 'w', 'o', ' ', 'c', 'o', 'n', 'f', 'e', 'r', 'e', 'n', 'c', 'e', 's', ' ', 'u', 'n', 'd', 'e', 'r', ' ', 't', 'h', 'e', ' ', 'a', 'u', 's', 'p', 'i', 'c', 'e', 's', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 'L', 'e', 'a', 'g', 'u', 'e', ' ', 'o', 'f', ' ', 'A', 'r', 'a', 'b', ' ', 'S', 't', 'a', 't', 'e', 's', '.'], ['M', 'y', ' ', 'a', 't', 't', 'e', 'n', 't', 'i', 'o', 'n', ' ', 'w', 'a', 's', ' ', 'n', 'o', 't', ' ', 'o', 'n', 'l', 'y', ' ', 'c', 'a', 's', 't', ' ', 'o', 'n', ' ', 't', 'r', 'a', 'n', 's', 'l', 'a', 't', 'i', 'o', 'n', '-', 'r', 'e', 'l', 'a', 't', 'e', 'd', ' ', 'j', 'o', 'b', 's', ',', ' ', 'b', 'u', 't', ' ', 'a', 'l', 's', 'o', ' ', 'o', 'n', ' ', 'l', 'i', 'f', 'e', '-', 'c', 'h', 'a', 'n', 'g', 'i', 'n', 'g', ' ', 'j', 'o', 'b', 's', ' ', 't', 'h', 'a', 't', ' ', 'w', 'i', 'l', 'l', ' ', 'h', 'e', 'l', 'p', ' ', 'm', 'e', ' ', 'i', 'n', ' ', 'a', 'c', 'h', 'i', 'e', 'v', 'i', 'n', 'g', ' ', 'm', 'y', ' ', 'g', 'o', 'a', 'l', 's', ' ', 'o', 'f', ' ', 's', 'p', 'r', 'e', 'a', 'd', 'i', 'n', 'g', ' ', 'k', 'n', 'o', 'w', 'l', 'e', 'd', 'g', 'e', ' ', 'a', 'n', 'd', ' ', 'e', 'n', 'h', 'a', 'n', 'c', 'i', 'n', 'g', ' ', 'i', 'n', 't', 'e', 'r', 'n', 'a', 't', 'i', 'o', 'n', 'a', 'l', ' ', 'r', 'e', 'l', 'a', 't', 'i', 'o', 'n', 's', 'h', 'i', 'p', 's', '.'], ['A', 's', ' ', 't', 'h', 'e', ' ', 'I', 'A', 'E', 'S', 'T', 'E', ' ', 'N', 'a', 't', 'i', 'o', 'n', 'a', 'l', ' ', 'S', 'e', 'c', 'r', 'e', 't', 'a', 'r', 'y', ' ', 'a', 'n', 'd', ' ', 't', 'h', 'e', ' ', 'H', 'e', 'a', 'd', ' ', 'o', 'f', ' ', 'S', 't', 'u', 'd', 'e', 'n', 't', ' ', 'E', 'x', 'c', 'h', 'a', 'n', 'g', 'e', ' ', 'i', 'n', ' ', 't', 'h', 'e', ' ', 'S', 'y', 'r', 'i', 'a', 'n', ' ', 'M', 'i', 'n', 'i', 's', 't', 'r', 'y', ' ', 'o', 'f', ' ', 'H', 'i', 'g', 'h', 'e', 'r', ' ', 'E', 'd', 'u', 'c', 'a', 't', 'i', 'o', 'n', ',', ' ', 'I', ' ', 'c', 'o', 'u', 'l', 'd', ' ', 'h', 'e', 'l', 'p', ' ', 'l', 'o', 't', 's', ' ', 'o', 'f', ' ', 's', 't', 'u', 'd', 'e', 'n', 't', 's', ' ', 't', 'o', ' ', 'p', 'u', 'r', 's', 'u', 'e', ' ', 't', 'h', 'e', 'i', 'r', ' ', 'h', 'i', 'g', 'h', 'e', 'r', ' ', 's', 't', 'u', 'd', 'i', 'e', 's', ' ', 'a', 'n', 'd', ' ', 'g', 'e', 't', ' ', 'i', 'n', 't', 'r', 'o', 'd', 'u', 'c', 'e', 'd', ' ', 't', 'o', ' ', 'd', 'i', 'f', 'f', 'e', 'r', 'e', 'n', 't', ' ', 'c', 'u', 'l', 't', 'u', 'r', 'e', 's', '.'], ['I', ' ', 'a', 'm', ' ', 'p', 'r', 'o', 'u', 'd', ' ', 'I', ' ', 'h', 'a', 'd', ' ', 't', 'h', 'e', ' ', 'c', 'h', 'a', 'n', 'c', 'e', ' ', 't', 'o', ' ', 'p', 'a', 'r', 't', 'i', 'c', 'i', 'p', 'a', 't', 'e', ' ', 'i', 'n', ' ', 's', 't', 'r', 'e', 'n', 'g', 't', 'h', 'e', 'n', 'i', 'n', 'g', ' ', 'i', 'n', 't', 'e', 'r', 'c', 'u', 'l', 't', 'u', 'r', 'a', 'l', ' ', 'a', 'n', 'd', ' ', 'e', 'd', 'u', 'c', 'a', 't', 'i', 'o', 'n', 'a', 'l', ' ', 'r', 'e', 'l', 'a', 't', 'i', 'o', 'n', 's', ' ', 'a', 's', ' ', 'w', 'e', 'l', 'l', ' ', 'a', 's', ' ', 'i', 'n', ' ', 'r', 'e', 'b', 'u', 'i', 'l', 'd', 'i', 'n', 'g', ' ', 'h', 'o', 'p', 'e', ' ', 'a', 'n', 'd', ' ', 't', 'r', 'a', 'n', 's', 'f', 'o', 'r', 'm', 'i', 'n', 'g', ' ', 'l', 'i', 'v', 'e', 's', ' ', 'o', 'f', ' ', 'S', 'y', 'r', 'i', 'a', 'n', 's', ' ', 'f', 'r', 'o', 'm', ' ', 'b', 'e', 'i', 'n', 'g', ' ', 'h', 'e', 'l', 'p', 'l', 'e', 's', 's', ' ', 'r', 'e', 'f', 'u', 'g', 'e', 'e', 's', ' ', 'i', 'n', 't', 'o', ' ', 'p', 'r', 'o', 'd', 'u', 'c', 't', 'i', 'v', 'e', ' ', 'a', 'c', 't', 'i', 'v', 'e', ' ', 'p', 'l', 'a', 'y', 'e', 'r', 's', ' ', 'i', 'n', ' ', 't', 'h', 'e', ' ', 'r', 'e', 'c', 'o', 'n', 's', 't', 'r', 'u', 'c', 't', 'i', 'o', 'n', ' ', 'o', 'f', ' ', 'S', 'y', 'r', 'i', 'a', '.'], ['P', 'u', 'r', 's', 'u', 'i', 'n', 'g', ' ', 't', 'h', 'i', 's', ' ', 'p', 'r', 'o', 'g', 'r', 'a', 'm', ' ', 'w', 'o', 'u', 'l', 'd', ' ', 'h', 'e', 'l', 'p', ' ', 'r', 'e', 'a', 'l', 'i', 'z', 'e', ' ', 'm', 'y', ' ', 'g', 'o', 'a', 'l', 's', '.'], ['F', 'i', 'r', 's', 't', ',', ' ', 's', 'p', 'e', 'c', 'i', 'a', 'l', 'i', 'z', 'i', 'n', 'g', ' ', 'i', 'n', ' ', 'l', 'i', 'n', 'g', 'u', 'i', 's', 't', 'i', 'c', 's', ' ', 'e', 'n', 'a', 'b', 'l', 'e', 's', ' ', 'm', 'e', ' ', 't', 'o', ' ', 'p', 'u', 'r', 's', 'u', 'e', ' ', 'a', ' ', 'c', 'a', 'r', 'e', 'e', 'r', ' ', 'a', 's', ' ', 'a', ' ', 't', 'r', 'a', 'n', 's', 'l', 'a', 't', 'o', 'r', ' ', 'i', 'n', ' ', 'a', 'n', ' ', 'i', 'n', 't', 'e', 'r', 'n', 'a', 't', 'i', 'o', 'n', 'a', 'l', ' ', 'h', 'i', 'g', 'h', ' ', 'p', 'r', 'o', 'f', 'i', 'l', 'e', ' ', 'o', 'r', 'g', 'a', 'n', 'i', 'z', 'a', 't', 'i', 'o', 'n', ' ', 't', 'o', ' ', 't', 'r', 'a', 'n', 's', 'l', 'a', 't', 'e', ' ', 't', 'h', 'e', ' ', 'p', 'a', 'i', 'n', 's', ' ', 'a', 'n', 'd', ' ', 'h', 'o', 'p', 'e', 's', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 'o', 'p', 'p', 'r', 'e', 's', 's', 'e', 'd', '.'], ['I', ' ', 'w', 'i', 'l', 'l', ' ', 'u', 's', 'e', ' ', 't', 'r', 'a', 'n', 's', 'l', 'a', 't', 'i', 'o', 'n', ' ', 't', 'o', ' ', 'g', 'e', 't', ' ', 'i', 'n', 't', 'r', 'o', 'd', 'u', 'c', 'e', 'd', ' ', 't', 'o', ' ', 'd', 'i', 'f', 'f', 'e', 'r', 'e', 'n', 't', ' ', 'f', 'i', 'e', 'l', 'd', 's', ' ', 'o', 'f', ' ', 'k', 'n', 'o', 'w', 'l', 'e', 'd', 'g', 'e', ',', ' ', 'd', 'i', 'v', 'e', 'r', 's', 'e', ' ', 'c', 'u', 'l', 't', 'u', 'r', 'e', 's', ' ', 'a', 'n', 'd', ' ', 't', 'h', 'e', ' ', 'l', 'a', 't', 'e', 's', 't', ' ', 'd', 'e', 'v', 'e', 'l', 'o', 'p', 'm', 'e', 'n', 't', 's', '.'], ['T', 'h', 'i', 's', ' ', 'c', 'o', 'n', 't', 'r', 'i', 'b', 'u', 't', 'e', 's', ' ', 't', 'o', ' ', 't', 'h', 'e', ' ', 'r', 'e', 'c', 'o', 'n', 's', 't', 'r', 'u', 'c', 't', 'i', 'o', 'n', ' ', 'o', 'f', ' ', 'S', 'y', 'r', 'i', 'a', '.'], ['F', 'u', 'r', 't', 'h', 'e', 'r', 'm', 'o', 'r', 'e', ',', ' ', 'E', 'n', 'g', 'l', 'i', 's', 'h', ' ', 'S', 't', 'u', 'd', 'i', 'e', 's', ' ', 'i', 's', ' ', 'v', 'i', 't', 'a', 'l', ' ', 'f', 'o', 'r', ' ', 'f', 'i', 'n', 'd', 'i', 'n', 'g', ' ', 'o', 'u', 't', ' ', 'p', 'o', 'i', 'n', 't', 's', ' ', 'o', 'f', ' ', 'c', 'o', 'n', 'v', 'e', 'r', 'g', 'e', 'n', 'c', 'e', ' ', 'b', 'e', 't', 'w', 'e', 'e', 'n', ' ', 'A', 'r', 'a', 'b', 's', ' ', 'a', 'n', 'd', ' ', 't', 'h', 'e', ' ', 'r', 'e', 's', 't', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 'w', 'o', 'r', 'l', 'd', ',', ' ', 'c', 'o', 'r', 'r', 'e', 'c', 't', 'i', 'n', 'g', ' ', 'm', 'i', 's', 'c', 'o', 'n', 'c', 'e', 'p', 't', 'i', 'o', 'n', 's', ',', ' ', 'a', 'n', 'd', ' ', 'd', 'e', 'f', 'y', 'i', 'n', 'g', ' ', 's', 't', 'e', 'r', 'e', 'o', 't', 'y', 'p', 'e', 's', '.'], ['I', 't', ' ', 'w', 'o', 'u', 'l', 'd', ' ', 's', 'e', 'r', 'v', 'e', ' ', 'a', 's', ' ', 'a', ' ', 's', 'p', 'r', 'i', 'n', 'g', 'b', 'o', 'a', 'r', 'd', ' ', 'f', 'o', 'r', ' ', 'o', 'p', 'e', 'n', 'n', 'e', 's', 's', ' ', 'a', 'n', 'd', ' ', 'a', 'c', 'c', 'e', 'p', 't', 'a', 'n', 'c', 'e', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', '“', 'O', 't', 'h', 'e', 'r', '”', '.'], ['I', 't', ' ', 'w', 'i', 'l', 'l', ' ', 'h', 'o', 'p', 'e', 'f', 'u', 'l', 'l', 'y', ' ', 'c', 'o', 'n', 't', 'r', 'i', 'b', 'u', 't', 'e', ' ', 't', 'o', ' ', 't', 'u', 'r', 'n', 'i', 'n', 'g', ' ', 't', 'h', 'e', ' ', 'w', 'o', 'r', 'l', 'd', ' ', 'i', 'n', 't', 'o', ' ', 'a', ' ', 'm', 'o', 'r', 'e', ' ', 'h', 'a', 'r', 'm', 'o', 'n', 'i', 'o', 'u', 's', ',', ' ', 'w', 'e', 'l', 'l', '-', 'i', 'n', 'f', 'o', 'r', 'm', 'e', 'd', ' ', 'a', 'n', 'd', ' ', 's', 'e', 'c', 'u', 'r', 'e', ' ', 'p', 'l', 'a', 'c', 'e', ' ', 't', 'o', ' ', 'l', 'i', 'v', 'e', ' ', 'i', 'n', '.'], ['I', 'n', ' ', 's', 'h', 'o', 'r', 't', ',', ' ', 'm', 'y', ' ', 'p', 'r', 'o', 'v', 'e', 'n', ' ', 'a', 'b', 'i', 'l', 'i', 't', 'i', 'e', 's', ' ', 'w', 'o', 'u', 'l', 'd', ' ', 'm', 'a', 'k', 'e', ' ', 'm', 'e', ' ', 'a', ' ', 'p', 'e', 'r', 'f', 'e', 'c', 't', ' ', 'f', 'i', 't', '.'], ['M', 'y', ' ', 'a', 'm', 'b', 'i', 't', 'i', 'o', 'n', ' ', 't', 'o', ' ', 'f', 'u', 'r', 't', 'h', 'e', 'r', ' ', 'd', 'e', 'v', 'e', 'l', 'o', 'p', ' ', 'm', 'y', 's', 'e', 'l', 'f', ' ', 'a', 'n', 'd', ' ', 'm', 'y', ' ', 't', 'h', 'i', 'r', 's', 't', ' ', 'f', 'o', 'r', ' ', 'e', 'm', 'p', 'l', 'o', 'y', 'i', 'n', 'g', ' ', 't', 'h', 'e', ' ', 't', 'h', 'i', 'n', 'g', 's', ' ', 'I', ' ', 'l', 'e', 'a', 'r', 'n', ' ', 'i', 'n', ' ', 'h', 'e', 'l', 'p', 'i', 'n', 'g', ' ', 'o', 't', 'h', 'e', 'r', 's', ' ', 'e', 's', 'p', 'e', 'c', 'i', 'a', 'l', 'l', 'y', ' ', 'S', 'y', 'r', 'i', 'a', 'n', 's', ' ', 'i', 'n', ' ', 't', 'i', 'm', 'e', 's', ' ', 'o', 'f', ' ', 'w', 'a', 'r', ' ', 'a', 'n', 'd', ' ', 'l', 'a', 't', 'e', 'r', ' ', 'o', 'n', ' ', 'i', 'n', ' ', 'r', 'e', 'b', 'u', 'i', 'l', 'd', 'i', 'n', 'g', ' ', 'S', 'y', 'r', 'i', 'a', ' ', 'i', 's', ' ', 't', 'h', 'e', ' ', 's', 't', 'r', 'o', 'n', 'g', 'e', 's', 't', ' ', 'm', 'o', 't', 'i', 'v', 'a', 't', 'i', 'o', 'n', ' ', 't', 'o', ' ', 'k', 'e', 'e', 'p', ' ', 'm', 'e', ' ', 'w', 'o', 'r', 'k', 'i', 'n', 'g', ' ', 'r', 'e', 'l', 'e', 'n', 't', 'l', 'e', 's', 's', 'l', 'y', '.'], ['T', 'h', 'i', 's', ' ', 'm', 'a', 'k', 'e', 's', ' ', 'm', 'e', ' ', 'm', 'e', 'e', 't', ' ', 't', 'h', 'e', ' ', 's', 't', 'a', 'n', 'd', 'a', 'r', 'd', 's', ' ', 'o', 'f', ' ', 'y', 'o', 'u', 'r', ' ', 'p', 'r', 'e', 's', 't', 'i', 'g', 'i', 'o', 'u', 's', ' ', 'i', 'n', 's', 't', 'i', 't', 'u', 't', 'i', 'o', 'n', '.']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIrsTkGG7S8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ph = gensim.models.Phrases(vocab, min_count=1, threshold=-1, scoring='npmi')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iU-jMjFV5Mtc",
        "colab_type": "code",
        "outputId": "94443fc1-5ece-4963-8421-b025c15c8d17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "p = gensim.models.Phrases(ph[vocab], min_count=1, threshold=-1, scoring='npmi')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjI7HLvM5Q1a",
        "colab_type": "code",
        "outputId": "fbff6b77-9dd4-4dbe-8958-86d630141175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "p2= gensim.models.Phrases(p[phrases[vocab]], min_count=1, threshold=0, scoring='npmi')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19mUWl855ZD7",
        "colab_type": "code",
        "outputId": "a9f7144e-8061-4da5-a3d7-278d22f6f607",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "p3=Phrases (p2[p[phrases[vocab]]], min_count=1, threshold=0.1, scoring='npmi')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urvOaTCA5cyK",
        "colab_type": "code",
        "outputId": "2331a565-e501-40ab-b249-9a42aa458bcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "print(list(p3[p2[p[vocab]]]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['A_m', 'i_d', ' _t', 'h_e', ' _c', 'r_i', 'e_s', ' _o', 'f_ ', 'w_a', 'r', ',', ' _d', 'e_a', 't_h', ',', ' _a', 'n_d', ' _p', 'o', 'v_e', 'r_t', 'y', ',', ' _l', 'o_u', 'd_ ', 's', 'o_u', 'n_d', 's_ ', 'd_e', 'e_p', ' _d', 'o_w', 'n_ ', 'o_f', ' _m', 'e_ ', 'a_r', 'e_ ', 'r_i', 's', 'i_n', 'g', ' _m', 'e_ ', 'u_p', ',', ' _c', 'a_l', 'l_i', 'n_g', ' _m', 'e_ ', 't_o', ' _f', 'i_n', 'd_ ', 'm', 'y_ ', 'w_a', 'y_ ', 'o_u', 't_ ', 'o_f', ' _t', 'h_e', ' _r', 'u_b', 'b_l', 'e', ',', ' _f', 'r_e', 'e_ ', 'm', 'y_ ', 'o_w', 'n_ ', 's', 'e_l', 'f_ ', 'w_i', 't_h', ' _t', 'h_e', ' _w', 'e_a', 'p_o', 'n_ ', 'o_f', ' _k', 'n_o_w_l', 'e_d', 'g_e', ' _a', 'n_d', ' _r', 'e_v', 'i', 'v_e', ' _m', 'y_ ', 'd_y', 'i_n', 'g', ' _c', 'o_u', 'n_t', 'r_y', '.'], ['A_r', 'm_e', 'd_ ', 'w_i', 't_h', ' _h', 'o_p', 'e', ',', ' ', 'I_ ', 'h_a', 'v_e', ' _d', 'e_c', 'i_d', 'e_d', ' _t', 'o_ ', 's_t', 'a_r', 't_ ', 'm', 'y_ ', 'o_w', 'n_ ', 'j_o', 'u_r', 'n_e', 'y_ ', 'i_n', ' _s', 'e_a_r', 'c_h', ' _f', 'o_r', ' _w', 'a_y', 's_ ', 't_o', ' _b', 'e_t', 't_e', 'r_ ', 'm', 'y_ ', 'l_i', 'f_e', ' _a', 'n_d', ' _o', 't_h', 'e_r', 's_’', '.'], ['B', 'r_i', 'd_g', 'i_n', 'g', ' _t', 'h_e', ' _w', 'i_d', 'e_n', 'i_n', 'g', ' _g', 'a_p', ' _b', 'e_t', 'w_e', 'e_n', ' _S', 'y', 'r_i', 'a_ ', 'a_n', 'd_ ', 't_h', 'e_ ', 'r_e', 's_t', ' _o', 'f_ ', 't_h', 'e_ ', 'w', 'o_r', 'l_d', ' _i', 's_ ', 'v_i', 't_a', 'l_ ', 'f', 'o_r', ' _s', 'h_a', 'p', 'i_n', 'g', ' _a', ' _b', 'e_t', 't_e', 'r_ ', 'f_u', 't_u', 'r_e', '.'], ['S', 'i_n', 'c_e', ' _E', 'n_g', 'l_i', 's_h', ' _s', 'p_e', 'a_k', 'i_n', 'g', ' _c', 'o_u', 'n_t', 'r_i', 'e_s', ' _h', 'a', 'v_e', ' _a', ' _l', 'e_a', 'd_i', 'n_g', ' _r', 'o_l', 'e_ ', 'i_n', ' _t', 'o_d', 'a_y', '’', 's_ ', 'w', 'o_r', 'l_d', ' _a', 'n_d', ' _E', 'n_g', 'l_i', 's_h', ' _i', 's_ ', 't_h', 'e_ ', 'l_i', 'n_g', 'u_a', ' _f', 'r_a', 'n_c', 'a', ',', ' _a', 'n_ ', 'M_A', ' _i', 'n_ ', 'E', 'n_g', 'l_i', 's_h', ' _S', 't_u', 'd_i', 'e_s', ' _i', 's_ ', 'p_e', 'r', 'f_e', 'c', 't_ ', 'f', 'o_r', ' _n', 'o_t', ' _o', 'n', 'l_y', ' _m', 'a', 's_t', 'e_r', 'i_n', 'g', ' _E', 'n_g', 'l_i', 's_h', ' _l', 'a_n', 'g_u', 'a_g', 'e_ ', 'b_u', 't_ ', 'a_l', 's', 'o_ ', 'f', 'o_r', ' _g', 'e_t', 't_i', 'n_g', ' _w', 'e_l', 'l_-', 'i_n', 'f', 'o_r', 'm_e', 'd_ ', 'a_b', 'o_u', 't_ ', 't_h', 'e_ ', 'h_i', 's_t', 'o_r', 'y', ',', ' _l', 'a_n', 'g_u', 'a_g', 'e_ ', 'a_n', 'd_ ', 'c_u', 'l', 't_u', 'r_e', ' _o', 'f_ ', 's_u', 'c_h', ' _c', 'o_u', 'n_t', 'r_i', 'e_s', '.'], ['W_h', 'a_t', ' _c', 'a_n', ' _b', 'e_ ', 'b_e', 't', 't_e', 'r_ ', 't_h', 'a_n', ' _t', 'h_e', ' _h', 'e_a', 'r_t', ' _o', 'f_ ', 'E', 'u_r', 'o_p', 'e_ ', 't_o', ' _b', 'e_ ', 'm', 'y_ ', 's_t', 'o_p', ' _f', 'o_r', ' _g', 'e_t', 't_i', 'n_g', ' _c', 'l_o', 's', 'e_l', 'y_ ', 'i_n', ' _t', 'o_u', 'c_h', ' _w', 'i_t', 'h_ ', 't_h', 'e_ ', 'c_u', 'l', 't_u', 'r_e', 's_ ', 'o_f', ' _t', 'h_o', 's', 'e_ ', 'c', 'o_u', 'n_t', 'r_i', 'e_s', '?_!'], ['I_ ', 'f', 'o_u', 'n_d', ' _m', 'y_ ', 'h_a', 'v_e', 'n_ ', 'i_n', ' _y', 'o_u', 'r_ ', 'p_r', 'e_s', 't_i', 'g_i', 'o_u', 's_ ', 'u_n', 'i', 'v_e', 'r_s', 'i_t', 'y_ ', 'w_i', 't_h', ' _i', 't', 's_ ', 'u_n', 'i_q', 'u', 'e_ ', 'M_A', ' _p', 'r_o', 'g', 'r_a', 'm_ ', 't_o', ' _b', 'e_ ', 'm', 'y_ ', 'f_i', 'n', 'a_l', ' _d', 'e_s', 't_i', 'n', 'a_t', 'i_o', 'n_ ', 'f', 'o_r', ' _m', 'a_n', 'y_ ', 'r_e', 'a', 's', 'o_n', 's_.'], ['F_i', 'r_s', 't', ',', ' _i', 't_ ', 'i_s', ' _h', 'i_g', 'h_l', 'y_ ', 'a_c', 'c', 'l_a', 'i', 'm_e', 'd_ ', 'l_o', 'c_a', 'l_l', 'y_ ', 'a_n', 'd_ ', 'i_n', 't_e', 'r_n', 'a_t', 'i_o', 'n', 'a_l', 'l_y', '.'], ['S', 'e_c', 'o_n', 'd', ',', ' _t', 'h_e', ' _c', 'o_u', 'r_s', 'e_ ', 'g_i', 'v_e', 's_ ', 't_h', 'e_ ', 'a_b', 'i_l', 'i_t', 'y_ ', 't_o', ' _s', 'p_e', 'c_i', 'a_l', 'i_z', 'e_ ', 'i_n', ' _l', 'i_n', 'g_u', 'i_s', 't_i', 'c', 's_ ', 'w_h', 'i_c', 'h_ ', 'i_s', ' _i', 'n_t', 'e_r', 'r_e', 'l_a', 't_e', 'd_ ', 't_o', ' _t', 'r_a', 'n_s', 'l_a', 't_i', 'o_n', ',', ' _m', 'y_ ', 'P_g', 'D_.'], ['s_p', 'e_c', 'i', 'a_l', 'i_z', 'a_t', 'i_o', 'n_.'], ['F', 'u_r', 't_h', 'e_r', 'm', 'o_r', 'e', ',', ' _y', 'o_u', 'r_ ', 'a_c', 'a_d_e_m', 'i_c', ' _s', 't_a', 'f_f', ' _b', 'o', 'a', 's_t', ' _i', 'n_t', 'e_r', 'n', 'a_t', 'i_o', 'n', 'a_l', ' _r', 'e_p', 'u_t', 'a_t', 'i_o', 'n_ ', 'f', 'o_r', ' _t', 'h_e', 'i_r', ' _p', 'r_o', 'f_e', 's', 's', 'i_o', 'n', 'a_l', 'i_s', 'm_.'], ['M', 'o_r', 'e_o', 'v_e', 'r', ',', ' _t', 'h_e', ' _c', 'o_u', 'r_s', 'e_ ', 'i_s', ' _n', 'o_t', ' _o', 'n', 'l_y', ' _f', 'i_n', 'e_-', 't_u', 'n_e', 'd_ ', 't_o', ' _t', 'h_e', ' ', 'j_o', 'b_ ', 'm_a', 'r', 'k_e', 't_ ', 'n_e', 'e_d', 's_ ', 'b_u', 't_ ', 'a_l', 's', 'o_ ', 's', 'e_r', 'v_e', 's_ ', 'a', 's_ ', 'a_ ', 's_p', 'r_i', 'n_g', 'b_o', 'a_r', 'd_ ', 'i_n', 't_o', ' _f', 'u_r', 't_h', 'e_r', ' _a', 'c_a', 'd_e', 'm_i', 'c', ' _s', 't_u', 'd_y', '.'], ['I', 't_ ', 'w_i_l_l', ' _e', 'q_u', 'i_p', ' _m', 'e_ ', 'w_i', 't_h', ' _u', 'p_-', 't_o', '-_d', 'a_t', 'e_ ', 'k_n_o_w', 'l', 'e_d', 'g_e', ',', ' _c', 'r_i', 't_i', 'c_a', 'l_ ', 'p_e', 'r_s', 'p_e', 'c', 't_i', 'v_e', ',', ' _i', 'n_t', 'e_r', 'p_r', 'e_t', 'i', 'v_e', ' _a', 'n_d', ' _a', 'n', 'a_l', 'y', 't_i', 'c_a', 'l_ ', 's', 'k_i', 'l_l', 's', ',', ' _a', 'r', 'g_u', 'm_e', 'n_t', 'a_t', 'i', 'v_e', ' _w', 'r_i', 't_i', 'n_g', ',', ' _a', 'n_d', ' _a', 'c_a', 'd_e', 'm_i', 'c', ' _r', 'e_s', 'e_a_r', 'c_h', ' _t', 'o', 'o_l', 's_.'], ['M', 'y_ ', 'u_n', 'd_e', 'r', 'g', 'r_a', 'd_u', 'a_t', 'e_ ', 's_t', 'u_d', 'y_ ', 'o_f', ' _E', 'n_g', 'l_i', 's_h', ' _l', 'a_n', 'g_u', 'a_g', 'e_ ', 'a_n', 'd_ ', 'l_i', 't_e', 'r_a', 't_u', 'r_e', ' _e', 'n', 'a_b', 'l', 'e_d', ' _m', 'e_ ', 't_o', ' _g', 'e_t', ' _m', 'o_r', 'e_ ', 'a_c', 'q_u', 'a', 'i_n', 't_e', 'd_ ', 'w_i', 't_h', ' _b', 'o_t', 'h_ ', 'E', 'n_g', 'l_i', 's_h', ' _l', 'a_n', 'g_u', 'a_g', 'e_ ', 'a_n', 'd_ ', 'c_u', 'l', 't_u', 'r_e', '.'], ['I_ ', 'g_o', 't_ ', 'a_ ', 'm', 'o_r', 'e_ ', 's_p', 'e_c', 'i', 'a_l', 'i_z', 'e_d', ' _l', 'o', 'o_k', ' _i', 'n_t', 'o_ ', 't_r', 'a_n', 's', 'l_a', 't_i', 'o_n', ',', ' _w', 'h_i', 'c_h', ' _i', 's_ ', 'a_ ', 'm_e', 'a_n', 's_ ', 'o_f', ' _k', 'n_o_w_l', 'e_d', 'g_e', ' _t', 'r_a', 'n_s', 'f_e', 'r_ ', 'a_n', 'd_ ', 'i_n', 't_e', 'r', 'c_u', 'l', 't_u', 'r_a', 'l_ ', 'c', 'o_m', 'm_u', 'n_i', 'c_a', 't_i', 'o_n', ',', ' _t', 'h', 'r_o', 'u', 'g_h', ' _m', 'y_ ', 'p_o', 's_t', 'g', 'r_a', 'd_u', 'a_t', 'e_ ', 'd_i', 'p_l', 'o_m', 'a_ ', 'i_n', ' _T', 'r_a', 'n_s', 'l_a', 't_i', 'o_n', ' _a', 'n_d', ' _A', 'r_a', 'b_i', 'z', 'a_t', 'i_o', 'n_.'], ['I_ ', 'a_m', ' _a', ' _c', 'e_r', 't_i', 'f_i', 'e_d', ' _f', 'r_e', 'e_l', 'a_n', 'c_e', ' _t', 'r_a', 'n_s', 'l_a', 't_o', 'r_.'], ['I_ ', 'w', 'o_r', 'k_e', 'd_ ', 'a', 's_ ', 'a_ ', 't_r', 'a_n', 's', 'l_a', 't_o', 'r_ ', 'i_n', ' _t', 'h_e', ' _S', 'y', 'r_i', 'a_n', ' _P', 'a_r', 'l_i', 'a_m', 'e_n', 't_ ', 'a_n', 'd_ ', 'a', 's_ ', 'a_ ', 't_r', 'a_n', 's', 'l_a', 't_i', 'o_n', ' _p', 'r_o', 'j', 'e_c', 't_ ', 'm_a', 'n', 'a_g', 'e_r', ' _f', 'o_r', ' _S', 'y', 'r_i', 'a_n', ' _S', 'o_c', 'i_e', 't_y', ' _f', 'o_r', ' _S', 'c_i', 'e_n', 't_i', 'f_i', 'c', ' _R', 'e_s', 'e_a_r', 'c_h', '.'], ['M', 'y_ ', 'h_a', 'r', 'd_ ', 'w', 'o_r', 'k', ' _p', 'a', 'i_d', ' _o', 'f_f', ' _w', 'h_e', 'n_ ', 'I_ ', 'g_o', 't_ ', 't_h', 'e_ ', 'c_h', 'a_n', 'c_e', ' _t', 'o_ ', 'w', 'o_r', 'k', ' _a', 's_ ', 'a_ ', 't_r', 'a_n', 's', 'l_a', 't_o', 'r_ ', 'i_n', ' _a', ' _p', 'u_b', 'l_i', 's_h', 'i_n', 'g', ' _h', 'o_u', 's', 'e_ ', 'i_n', ' _L', 'e_b', 'a_n', 'o_n', ' _a', 'n_d', ' _a', 's_ ', 'a_n', ' _i', 'n_t', 'e_r', 'p_r', 'e_t', 'e_r', ' _i', 'n_ ', 't_w', 'o_ ', 'c', 'o_n', 'f_e', 'r_e', 'n_c', 'e_s', ' _u', 'n_d', 'e_r', ' _t', 'h_e', ' _a', 'u_s', 'p', 'i_c', 'e_s', ' _o', 'f_ ', 't_h', 'e_ ', 'L_e', 'a_g', 'u', 'e_ ', 'o_f', ' _A', 'r_a', 'b_ ', 'S_t', 'a_t', 'e_s', '.'], ['M', 'y_ ', 'a_t', 't_e', 'n_t', 'i_o', 'n_ ', 'w_a', 's_ ', 'n_o', 't_ ', 'o_n', 'l_y', ' _c', 'a', 's_t', ' _o', 'n_ ', 't_r', 'a_n', 's', 'l_a', 't_i', 'o_n', '-', 'r_e', 'l_a', 't_e', 'd_ ', 'j_o', 'b_s', ',', ' _b', 'u_t', ' _a', 'l_s', 'o_ ', 'o_n', ' _l', 'i_f', 'e_-', 'c_h', 'a_n', 'g_i', 'n_g', ' ', 'j_o', 'b_s', ' _t', 'h_a', 't_ ', 'w_i_l_l', ' _h', 'e_l', 'p_ ', 'm_e', ' _i', 'n_ ', 'a_c', 'h_i', 'e_v', 'i_n', 'g', ' _m', 'y_ ', 'g_o', 'a_l', 's_ ', 'o_f', ' _s', 'p_r', 'e_a', 'd_i', 'n_g', ' _k', 'n_o_w_l', 'e_d', 'g_e', ' _a', 'n_d', ' _e', 'n', 'h_a', 'n_c', 'i_n', 'g', ' _i', 'n_t', 'e_r', 'n', 'a_t', 'i_o', 'n', 'a_l', ' _r', 'e_l', 'a_t', 'i_o', 'n_s', 'h_i', 'p', 's_.'], ['A', 's_ ', 't_h', 'e_ ', 'I_A', 'E_S', 'T_E', ' _N', 'a_t', 'i_o', 'n', 'a_l', ' _S', 'e_c', 'r_e', 't_a', 'r_y', ' _a', 'n_d', ' _t', 'h_e', ' _H', 'e_a', 'd_ ', 'o_f', ' _S', 't_u', 'd_e', 'n_t', ' _E', 'x_c', 'h_a', 'n_g', 'e_ ', 'i_n', ' _t', 'h_e', ' _S', 'y', 'r_i', 'a_n', ' _M', 'i_n', 'i_s', 't_r', 'y_ ', 'o_f', ' _H', 'i_g', 'h_e', 'r_ ', 'E_d', 'u_c', 'a_t', 'i_o', 'n', ',', ' ', 'I_ ', 'c', 'o_u', 'l_d', ' _h', 'e_l', 'p_ ', 'l_o', 't', 's_ ', 'o_f', ' _s', 't_u', 'd_e', 'n_t', 's_ ', 't_o', ' _p', 'u_r', 's_u', 'e_ ', 't_h', 'e', 'i_r', ' _h', 'i_g', 'h_e', 'r_ ', 's_t', 'u_d', 'i_e', 's_ ', 'a_n', 'd_ ', 'g_e', 't_ ', 'i_n', 't_r', 'o_d_u_c', 'e_d', ' _t', 'o_ ', 'd_i', 'f_f', 'e_r', 'e_n', 't_ ', 'c_u', 'l', 't_u', 'r_e', 's_.'], ['I_ ', 'a_m', ' _p', 'r_o', 'u_d', ' ', 'I_ ', 'h_a', 'd_ ', 't_h', 'e_ ', 'c_h', 'a_n', 'c_e', ' _t', 'o_ ', 'p', 'a_r', 't_i', 'c_i', 'p', 'a_t', 'e_ ', 'i_n', ' _s', 't_r', 'e_n', 'g', 't_h', 'e_n', 'i_n', 'g', ' _i', 'n_t', 'e_r', 'c_u', 'l', 't_u', 'r_a', 'l_ ', 'a_n', 'd_ ', 'e_d', 'u_c', 'a_t', 'i_o', 'n', 'a_l', ' _r', 'e_l', 'a_t', 'i_o', 'n_s', ' _a', 's_ ', 'w_e', 'l_l', ' _a', 's_ ', 'i_n', ' _r', 'e_b', 'u_i', 'l_d', 'i_n', 'g', ' _h', 'o_p', 'e_ ', 'a_n', 'd_ ', 't_r', 'a_n', 's', 'f', 'o_r', 'm_i', 'n_g', ' _l', 'i', 'v_e', 's_ ', 'o_f', ' _S', 'y', 'r_i', 'a_n', 's_ ', 'f_r', 'o_m', ' _b', 'e', 'i_n', 'g', ' _h', 'e_l', 'p_l', 'e_s', 's_ ', 'r_e', 'f_u', 'g_e', 'e_s', ' _i', 'n_t', 'o_ ', 'p_r', 'o_d_u_c', 't_i', 'v_e', ' _a', 'c', 't_i', 'v_e', ' _p', 'l_a', 'y', 'e_r', 's_ ', 'i_n', ' _t', 'h_e', ' _r', 'e_c', 'o_n', 's_t', 'r_u', 'c', 't_i', 'o_n', ' _o', 'f_ ', 'S_y', 'r_i', 'a_.'], ['P', 'u_r', 's_u', 'i_n', 'g', ' _t', 'h_i', 's_ ', 'p_r', 'o_g', 'r_a', 'm_ ', 'w', 'o_u', 'l_d', ' _h', 'e_l', 'p_ ', 'r_e', 'a_l', 'i_z', 'e_ ', 'm', 'y_ ', 'g_o', 'a_l', 's_.'], ['F_i', 'r_s', 't', ',', ' _s', 'p_e', 'c_i', 'a_l', 'i_z', 'i_n', 'g', ' _i', 'n_ ', 'l_i', 'n_g', 'u_i', 's_t', 'i_c', 's_ ', 'e_n', 'a_b', 'l', 'e_s', ' _m', 'e_ ', 't_o', ' _p', 'u_r', 's_u', 'e_ ', 'a_ ', 'c_a', 'r_e', 'e_r', ' _a', 's_ ', 'a_ ', 't_r', 'a_n', 's', 'l_a', 't_o', 'r_ ', 'i_n', ' _a', 'n_ ', 'i_n', 't_e', 'r_n', 'a_t', 'i_o', 'n', 'a_l', ' _h', 'i_g', 'h_ ', 'p_r', 'o_f', 'i_l', 'e_ ', 'o_r', 'g_a', 'n_i', 'z', 'a_t', 'i_o', 'n_ ', 't_o', ' _t', 'r_a', 'n_s', 'l_a', 't_e', ' _t', 'h_e', ' _p', 'a', 'i_n', 's_ ', 'a_n', 'd_ ', 'h_o', 'p_e', 's_ ', 'o_f', ' _t', 'h_e', ' _o', 'p', 'p_r', 'e_s', 's', 'e_d', '.'], ['I_ ', 'w_i_l_l', ' _u', 's', 'e_ ', 't_r', 'a_n', 's', 'l_a', 't_i', 'o_n', ' _t', 'o_ ', 'g_e', 't_ ', 'i_n', 't_r', 'o_d_u_c', 'e_d', ' _t', 'o_ ', 'd_i', 'f_f', 'e_r', 'e_n', 't_ ', 'f_i', 'e_l', 'd', 's_ ', 'o_f', ' _k', 'n_o_w_l', 'e_d', 'g_e', ',', ' _d', 'i', 'v_e', 'r_s', 'e_ ', 'c_u', 'l', 't_u', 'r_e', 's_ ', 'a_n', 'd_ ', 't_h', 'e_ ', 'l_a', 't_e', 's_t', ' _d', 'e_v', 'e_l', 'o_p', 'm_e', 'n_t', 's_.'], ['T_h', 'i_s', ' _c', 'o_n', 't_r', 'i_b', 'u_t', 'e_s', ' _t', 'o_ ', 't_h', 'e_ ', 'r_e', 'c', 'o_n', 's_t', 'r_u', 'c', 't_i', 'o_n', ' _o', 'f_ ', 'S_y', 'r_i', 'a_.'], ['F', 'u_r', 't_h', 'e_r', 'm', 'o_r', 'e', ',', ' _E', 'n_g', 'l_i', 's_h', ' _S', 't_u', 'd_i', 'e_s', ' _i', 's_ ', 'v_i', 't_a', 'l_ ', 'f', 'o_r', ' _f', 'i_n', 'd_i', 'n_g', ' _o', 'u_t', ' _p', 'o', 'i_n', 't', 's_ ', 'o_f', ' _c', 'o_n', 'v_e', 'r', 'g_e', 'n_c', 'e_ ', 'b_e', 't_w', 'e_e', 'n_ ', 'A_r', 'a_b', 's_ ', 'a_n', 'd_ ', 't_h', 'e_ ', 'r_e', 's_t', ' _o', 'f_ ', 't_h', 'e_ ', 'w', 'o_r', 'l_d', ',', ' _c', 'o_r', 'r_e', 'c', 't_i', 'n_g', ' _m', 'i_s', 'c', 'o_n', 'c_e', 'p_t', 'i_o', 'n_s', ',', ' _a', 'n_d', ' _d', 'e_f', 'y', 'i_n', 'g', ' _s', 't_e', 'r_e', 'o_t', 'y_p', 'e_s', '.'], ['I', 't_ ', 'w', 'o_u', 'l_d', ' _s', 'e_r', 'v_e', ' _a', 's_ ', 'a_ ', 's_p', 'r_i', 'n_g', 'b_o', 'a_r', 'd_ ', 'f', 'o_r', ' _o', 'p_e', 'n', 'n_e', 's', 's_ ', 'a_n', 'd_ ', 'a_c', 'c_e', 'p_t', 'a_n', 'c_e', ' _o', 'f_ ', 't_h', 'e_ ', '“_O', 't_h', 'e_r', '”_.'], ['I', 't_ ', 'w_i_l_l', ' _h', 'o_p', 'e_f', 'u_l', 'l_y', ' _c', 'o_n', 't_r', 'i_b', 'u_t', 'e_ ', 't_o', ' _t', 'u_r', 'n_i', 'n_g', ' _t', 'h_e', ' _w', 'o_r', 'l_d', ' _i', 'n_t', 'o_ ', 'a_ ', 'm', 'o_r', 'e_ ', 'h_a', 'r', 'm', 'o_n', 'i_o', 'u_s', ',', ' _w', 'e_l', 'l_-', 'i_n', 'f', 'o_r', 'm_e', 'd_ ', 'a_n', 'd_ ', 's', 'e_c', 'u_r', 'e_ ', 'p_l', 'a_c', 'e_ ', 't_o', ' _l', 'i', 'v_e', ' _i', 'n_.'], ['I', 'n_ ', 's_h', 'o_r', 't', ',', ' _m', 'y_ ', 'p_r', 'o', 'v_e', 'n_ ', 'a_b', 'i_l', 'i_t', 'i_e', 's_ ', 'w', 'o_u', 'l_d', ' _m', 'a_k', 'e_ ', 'm_e', ' _a', ' _p', 'e_r', 'f_e', 'c', 't_ ', 'f_i', 't', '.'], ['M', 'y_ ', 'a_m', 'b_i', 't_i', 'o_n', ' _t', 'o_ ', 'f_u', 'r_t', 'h_e', 'r_ ', 'd_e', 'v_e', 'l_o', 'p_ ', 'm', 'y_s', 'e_l', 'f_ ', 'a_n', 'd_ ', 'm', 'y_ ', 't_h', 'i_r', 's_t', ' _f', 'o_r', ' _e', 'm_p', 'l_o', 'y', 'i_n', 'g', ' _t', 'h_e', ' _t', 'h_i', 'n_g', 's_ ', 'I_ ', 'l', 'e_a', 'r_n', ' _i', 'n_ ', 'h_e', 'l_p', 'i_n', 'g', ' _o', 't_h', 'e_r', 's_ ', 'e_s', 'p_e', 'c_i', 'a_l', 'l_y', ' _S', 'y', 'r_i', 'a_n', 's_ ', 'i_n', ' _t', 'i', 'm_e', 's_ ', 'o_f', ' _w', 'a_r', ' _a', 'n_d', ' _l', 'a_t', 'e_r', ' _o', 'n_ ', 'i_n', ' _r', 'e_b', 'u_i', 'l_d', 'i_n', 'g', ' _S', 'y', 'r_i', 'a_ ', 'i_s', ' _t', 'h_e', ' _s', 't_r', 'o_n', 'g_e', 's_t', ' _m', 'o_t', 'i', 'v', 'a_t', 'i_o', 'n_ ', 't_o', ' _k', 'e_e', 'p_ ', 'm_e', ' _w', 'o_r', 'k_i', 'n_g', ' _r', 'e_l', 'e_n', 't_l', 'e_s', 's', 'l_y', '.'], ['T_h', 'i_s', ' _m', 'a_k', 'e_s', ' _m', 'e_ ', 'm_e', 'e_t', ' _t', 'h_e', ' _s', 't_a', 'n_d', 'a_r', 'd', 's_ ', 'o_f', ' _y', 'o_u', 'r_ ', 'p_r', 'e_s', 't_i', 'g_i', 'o_u', 's_ ', 'i_n', 's_t', 'i_t', 'u_t', 'i_o', 'n_.']]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcbQ5omM_wnJ",
        "colab_type": "code",
        "outputId": "3edd899f-4dbb-4a15-9a40-60370fb708ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "phrases_input = phrases[vocab]\n",
        "for i in range(100):\n",
        "    phrases = gensim.models.Phrases(phrases_input, min_count=1, threshold=-1, scoring='npmi')\n",
        "    phrases_input = phrases[phrases_input]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJZWBaJF_9HD",
        "colab_type": "code",
        "outputId": "b51184ab-674a-43c9-9bc2-3abb8196c24f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "print(list(phrases[phrases_input]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['A_m_i_d_ _t_h_e_ _c_r_i_e_s_ _o_f_ _w_a_r_,_ _d_e_a_t_h_,_ _a_n_d_ _p_o_v_e_r_t_y_,_ _l_o_u_d_ _s_o_u_n_d_s_ _d_e_e_p_ _d_o_w_n_ _o_f_ _m_e_ _a_r_e_ _r_i_s_i_n_g_ _m_e_ _u_p_,_ _c_a_l_l_i_n_g_ _m_e_ _t_o_ _f_i_n_d_ _m_y_ _w_a_y_ _o_u_t_ _o_f_ _t_h_e_ _r_u_b_b_l_e_,_ _f_r_e_e_ _m_y_ _o_w_n_ _s_e_l_f_ _w_i_t_h_ _t_h_e_ _w_e_a_p_o_n_ _o_f_ _k_n_o_w_l_e_d_g_e_ _a_n_d_ _r_e_v_i_v_e_ _m_y_ _d_y_i_n_g_ _c_o_u_n_t_r_y_.'], ['A_r_m_e_d_ _w_i_t_h_ _h_o_p_e_,_ _I_ _h_a_v_e_ _d_e_c_i_d_e_d_ _t_o_ _s_t_a_r_t_ _m_y_ _o_w_n_ _j_o_u_r_n_e_y_ _i_n_ _s_e_a_r_c_h_ _f_o_r_ _w_a_y_s_ _t_o_ _b_e_t_t_e_r_ _m_y_ _l_i_f_e_ _a_n_d_ _o_t_h_e_r_s_’_.'], ['B_r_i_d_g_i_n_g_ _t_h_e_ _w_i_d_e_n_i_n_g_ _g_a_p_ _b_e_t_w_e_e_n_ _S_y_r_i_a_ _a_n_d_ _t_h_e_ _r_e_s_t_ _o_f_ _t_h_e_ _w_o_r_l_d_ _i_s_ _v_i_t_a_l_ _f_o_r_ _s_h_a_p_i_n_g_ _a_ _b_e_t_t_e_r_ _f_u_t_u_r_e_.'], ['S_i_n_c_e_ _E_n_g_l_i_s_h_ _s_p_e_a_k_i_n_g_ _c_o_u_n_t_r_i_e_s_ _h_a_v_e_ _a_ _l_e_a_d_i_n_g_ _r_o_l_e_ _i_n_ _t_o_d_a_y_’_s_ _w_o_r_l_d_ _a_n_d_ _E_n_g_l_i_s_h_ _i_s_ _t_h_e_ _l_i_n_g_u_a_ _f_r_a_n_c_a_,_ _a_n_ _M_A_ _i_n_ _E_n_g_l_i_s_h_ _S_t_u_d_i_e_s_ _i_s_ _p_e_r_f_e_c_t_ _f_o_r_ _n_o_t_ _o_n_l_y_ _m_a_s_t_e_r_i_n_g_ _E_n_g_l_i_s_h_ _l_a_n_g_u_a_g_e_ _b_u_t_ _a_l_s_o_ _f_o_r_ _g_e_t_t_i_n_g_ _w_e_l_l_-_i_n_f_o_r_m_e_d_ _a_b_o_u_t_ _t_h_e_ _h_i_s_t_o_r_y_,_ _l_a_n_g_u_a_g_e_ _a_n_d_ _c_u_l_t_u_r_e_ _o_f_ _s_u_c_h_ _c_o_u_n_t_r_i_e_s_.'], ['W_h_a_t_ _c_a_n_ _b_e_ _b_e_t_t_e_r_ _t_h_a_n_ _t_h_e_ _h_e_a_r_t_ _o_f_ _E_u_r_o_p_e_ _t_o_ _b_e_ _m_y_ _s_t_o_p_ _f_o_r_ _g_e_t_t_i_n_g_ _c_l_o_s_e_l_y_ _i_n_ _t_o_u_c_h_ _w_i_t_h_ _t_h_e_ _c_u_l_t_u_r_e_s_ _o_f_ _t_h_o_s_e_ _c_o_u_n_t_r_i_e_s_?_!'], ['I_ _f_o_u_n_d_ _m_y_ _h_a_v_e_n_ _i_n_ _y_o_u_r_ _p_r_e_s_t_i_g_i_o_u_s_ _u_n_i_v_e_r_s_i_t_y_ _w_i_t_h_ _i_t_s_ _u_n_i_q_u_e_ _M_A_ _p_r_o_g_r_a_m_ _t_o_ _b_e_ _m_y_ _f_i_n_a_l_ _d_e_s_t_i_n_a_t_i_o_n_ _f_o_r_ _m_a_n_y_ _r_e_a_s_o_n_s_.'], ['F_i_r_s_t_,_ _i_t_ _i_s_ _h_i_g_h_l_y_ _a_c_c_l_a_i_m_e_d_ _l_o_c_a_l_l_y_ _a_n_d_ _i_n_t_e_r_n_a_t_i_o_n_a_l_l_y_.'], ['S_e_c_o_n_d_,_ _t_h_e_ _c_o_u_r_s_e_ _g_i_v_e_s_ _t_h_e_ _a_b_i_l_i_t_y_ _t_o_ _s_p_e_c_i_a_l_i_z_e_ _i_n_ _l_i_n_g_u_i_s_t_i_c_s_ _w_h_i_c_h_ _i_s_ _i_n_t_e_r_r_e_l_a_t_e_d_ _t_o_ _t_r_a_n_s_l_a_t_i_o_n_,_ _m_y_ _P_g_D_.'], ['s_p_e_c_i_a_l_i_z_a_t_i_o_n_.'], ['F_u_r_t_h_e_r_m_o_r_e_,_ _y_o_u_r_ _a_c_a_d_e_m_i_c_ _s_t_a_f_f_ _b_o_a_s_t_ _i_n_t_e_r_n_a_t_i_o_n_a_l_ _r_e_p_u_t_a_t_i_o_n_ _f_o_r_ _t_h_e_i_r_ _p_r_o_f_e_s_s_i_o_n_a_l_i_s_m_.'], ['M_o_r_e_o_v_e_r_,_ _t_h_e_ _c_o_u_r_s_e_ _i_s_ _n_o_t_ _o_n_l_y_ _f_i_n_e_-_t_u_n_e_d_ _t_o_ _t_h_e_ _j_o_b_ _m_a_r_k_e_t_ _n_e_e_d_s_ _b_u_t_ _a_l_s_o_ _s_e_r_v_e_s_ _a_s_ _a_ _s_p_r_i_n_g_b_o_a_r_d_ _i_n_t_o_ _f_u_r_t_h_e_r_ _a_c_a_d_e_m_i_c_ _s_t_u_d_y_.'], ['I_t_ _w_i_l_l_ _e_q_u_i_p_ _m_e_ _w_i_t_h_ _u_p_-_t_o_-_d_a_t_e_ _k_n_o_w_l_e_d_g_e_,_ _c_r_i_t_i_c_a_l_ _p_e_r_s_p_e_c_t_i_v_e_,_ _i_n_t_e_r_p_r_e_t_i_v_e_ _a_n_d_ _a_n_a_l_y_t_i_c_a_l_ _s_k_i_l_l_s_,_ _a_r_g_u_m_e_n_t_a_t_i_v_e_ _w_r_i_t_i_n_g_,_ _a_n_d_ _a_c_a_d_e_m_i_c_ _r_e_s_e_a_r_c_h_ _t_o_o_l_s_.'], ['M_y_ _u_n_d_e_r_g_r_a_d_u_a_t_e_ _s_t_u_d_y_ _o_f_ _E_n_g_l_i_s_h_ _l_a_n_g_u_a_g_e_ _a_n_d_ _l_i_t_e_r_a_t_u_r_e_ _e_n_a_b_l_e_d_ _m_e_ _t_o_ _g_e_t_ _m_o_r_e_ _a_c_q_u_a_i_n_t_e_d_ _w_i_t_h_ _b_o_t_h_ _E_n_g_l_i_s_h_ _l_a_n_g_u_a_g_e_ _a_n_d_ _c_u_l_t_u_r_e_.'], ['I_ _g_o_t_ _a_ _m_o_r_e_ _s_p_e_c_i_a_l_i_z_e_d_ _l_o_o_k_ _i_n_t_o_ _t_r_a_n_s_l_a_t_i_o_n_,_ _w_h_i_c_h_ _i_s_ _a_ _m_e_a_n_s_ _o_f_ _k_n_o_w_l_e_d_g_e_ _t_r_a_n_s_f_e_r_ _a_n_d_ _i_n_t_e_r_c_u_l_t_u_r_a_l_ _c_o_m_m_u_n_i_c_a_t_i_o_n_,_ _t_h_r_o_u_g_h_ _m_y_ _p_o_s_t_g_r_a_d_u_a_t_e_ _d_i_p_l_o_m_a_ _i_n_ _T_r_a_n_s_l_a_t_i_o_n_ _a_n_d_ _A_r_a_b_i_z_a_t_i_o_n_.'], ['I_ _a_m_ _a_ _c_e_r_t_i_f_i_e_d_ _f_r_e_e_l_a_n_c_e_ _t_r_a_n_s_l_a_t_o_r_.'], ['I_ _w_o_r_k_e_d_ _a_s_ _a_ _t_r_a_n_s_l_a_t_o_r_ _i_n_ _t_h_e_ _S_y_r_i_a_n_ _P_a_r_l_i_a_m_e_n_t_ _a_n_d_ _a_s_ _a_ _t_r_a_n_s_l_a_t_i_o_n_ _p_r_o_j_e_c_t_ _m_a_n_a_g_e_r_ _f_o_r_ _S_y_r_i_a_n_ _S_o_c_i_e_t_y_ _f_o_r_ _S_c_i_e_n_t_i_f_i_c_ _R_e_s_e_a_r_c_h_.'], ['M_y_ _h_a_r_d_ _w_o_r_k_ _p_a_i_d_ _o_f_f_ _w_h_e_n_ _I_ _g_o_t_ _t_h_e_ _c_h_a_n_c_e_ _t_o_ _w_o_r_k_ _a_s_ _a_ _t_r_a_n_s_l_a_t_o_r_ _i_n_ _a_ _p_u_b_l_i_s_h_i_n_g_ _h_o_u_s_e_ _i_n_ _L_e_b_a_n_o_n_ _a_n_d_ _a_s_ _a_n_ _i_n_t_e_r_p_r_e_t_e_r_ _i_n_ _t_w_o_ _c_o_n_f_e_r_e_n_c_e_s_ _u_n_d_e_r_ _t_h_e_ _a_u_s_p_i_c_e_s_ _o_f_ _t_h_e_ _L_e_a_g_u_e_ _o_f_ _A_r_a_b_ _S_t_a_t_e_s_.'], ['M_y_ _a_t_t_e_n_t_i_o_n_ _w_a_s_ _n_o_t_ _o_n_l_y_ _c_a_s_t_ _o_n_ _t_r_a_n_s_l_a_t_i_o_n_-_r_e_l_a_t_e_d_ _j_o_b_s_,_ _b_u_t_ _a_l_s_o_ _o_n_ _l_i_f_e_-_c_h_a_n_g_i_n_g_ _j_o_b_s_ _t_h_a_t_ _w_i_l_l_ _h_e_l_p_ _m_e_ _i_n_ _a_c_h_i_e_v_i_n_g_ _m_y_ _g_o_a_l_s_ _o_f_ _s_p_r_e_a_d_i_n_g_ _k_n_o_w_l_e_d_g_e_ _a_n_d_ _e_n_h_a_n_c_i_n_g_ _i_n_t_e_r_n_a_t_i_o_n_a_l_ _r_e_l_a_t_i_o_n_s_h_i_p_s_.'], ['A_s_ _t_h_e_ _I_A_E_S_T_E_ _N_a_t_i_o_n_a_l_ _S_e_c_r_e_t_a_r_y_ _a_n_d_ _t_h_e_ _H_e_a_d_ _o_f_ _S_t_u_d_e_n_t_ _E_x_c_h_a_n_g_e_ _i_n_ _t_h_e_ _S_y_r_i_a_n_ _M_i_n_i_s_t_r_y_ _o_f_ _H_i_g_h_e_r_ _E_d_u_c_a_t_i_o_n_,_ _I_ _c_o_u_l_d_ _h_e_l_p_ _l_o_t_s_ _o_f_ _s_t_u_d_e_n_t_s_ _t_o_ _p_u_r_s_u_e_ _t_h_e_i_r_ _h_i_g_h_e_r_ _s_t_u_d_i_e_s_ _a_n_d_ _g_e_t_ _i_n_t_r_o_d_u_c_e_d_ _t_o_ _d_i_f_f_e_r_e_n_t_ _c_u_l_t_u_r_e_s_.'], ['I_ _a_m_ _p_r_o_u_d_ _I_ _h_a_d_ _t_h_e_ _c_h_a_n_c_e_ _t_o_ _p_a_r_t_i_c_i_p_a_t_e_ _i_n_ _s_t_r_e_n_g_t_h_e_n_i_n_g_ _i_n_t_e_r_c_u_l_t_u_r_a_l_ _a_n_d_ _e_d_u_c_a_t_i_o_n_a_l_ _r_e_l_a_t_i_o_n_s_ _a_s_ _w_e_l_l_ _a_s_ _i_n_ _r_e_b_u_i_l_d_i_n_g_ _h_o_p_e_ _a_n_d_ _t_r_a_n_s_f_o_r_m_i_n_g_ _l_i_v_e_s_ _o_f_ _S_y_r_i_a_n_s_ _f_r_o_m_ _b_e_i_n_g_ _h_e_l_p_l_e_s_s_ _r_e_f_u_g_e_e_s_ _i_n_t_o_ _p_r_o_d_u_c_t_i_v_e_ _a_c_t_i_v_e_ _p_l_a_y_e_r_s_ _i_n_ _t_h_e_ _r_e_c_o_n_s_t_r_u_c_t_i_o_n_ _o_f_ _S_y_r_i_a_.'], ['P_u_r_s_u_i_n_g_ _t_h_i_s_ _p_r_o_g_r_a_m_ _w_o_u_l_d_ _h_e_l_p_ _r_e_a_l_i_z_e_ _m_y_ _g_o_a_l_s_.'], ['F_i_r_s_t_,_ _s_p_e_c_i_a_l_i_z_i_n_g_ _i_n_ _l_i_n_g_u_i_s_t_i_c_s_ _e_n_a_b_l_e_s_ _m_e_ _t_o_ _p_u_r_s_u_e_ _a_ _c_a_r_e_e_r_ _a_s_ _a_ _t_r_a_n_s_l_a_t_o_r_ _i_n_ _a_n_ _i_n_t_e_r_n_a_t_i_o_n_a_l_ _h_i_g_h_ _p_r_o_f_i_l_e_ _o_r_g_a_n_i_z_a_t_i_o_n_ _t_o_ _t_r_a_n_s_l_a_t_e_ _t_h_e_ _p_a_i_n_s_ _a_n_d_ _h_o_p_e_s_ _o_f_ _t_h_e_ _o_p_p_r_e_s_s_e_d_.'], ['I_ _w_i_l_l_ _u_s_e_ _t_r_a_n_s_l_a_t_i_o_n_ _t_o_ _g_e_t_ _i_n_t_r_o_d_u_c_e_d_ _t_o_ _d_i_f_f_e_r_e_n_t_ _f_i_e_l_d_s_ _o_f_ _k_n_o_w_l_e_d_g_e_,_ _d_i_v_e_r_s_e_ _c_u_l_t_u_r_e_s_ _a_n_d_ _t_h_e_ _l_a_t_e_s_t_ _d_e_v_e_l_o_p_m_e_n_t_s_.'], ['T_h_i_s_ _c_o_n_t_r_i_b_u_t_e_s_ _t_o_ _t_h_e_ _r_e_c_o_n_s_t_r_u_c_t_i_o_n_ _o_f_ _S_y_r_i_a_.'], ['F_u_r_t_h_e_r_m_o_r_e_,_ _E_n_g_l_i_s_h_ _S_t_u_d_i_e_s_ _i_s_ _v_i_t_a_l_ _f_o_r_ _f_i_n_d_i_n_g_ _o_u_t_ _p_o_i_n_t_s_ _o_f_ _c_o_n_v_e_r_g_e_n_c_e_ _b_e_t_w_e_e_n_ _A_r_a_b_s_ _a_n_d_ _t_h_e_ _r_e_s_t_ _o_f_ _t_h_e_ _w_o_r_l_d_,_ _c_o_r_r_e_c_t_i_n_g_ _m_i_s_c_o_n_c_e_p_t_i_o_n_s_,_ _a_n_d_ _d_e_f_y_i_n_g_ _s_t_e_r_e_o_t_y_p_e_s_.'], ['I_t_ _w_o_u_l_d_ _s_e_r_v_e_ _a_s_ _a_ _s_p_r_i_n_g_b_o_a_r_d_ _f_o_r_ _o_p_e_n_n_e_s_s_ _a_n_d_ _a_c_c_e_p_t_a_n_c_e_ _o_f_ _t_h_e_ _“_O_t_h_e_r_”_.'], ['I_t_ _w_i_l_l_ _h_o_p_e_f_u_l_l_y_ _c_o_n_t_r_i_b_u_t_e_ _t_o_ _t_u_r_n_i_n_g_ _t_h_e_ _w_o_r_l_d_ _i_n_t_o_ _a_ _m_o_r_e_ _h_a_r_m_o_n_i_o_u_s_,_ _w_e_l_l_-_i_n_f_o_r_m_e_d_ _a_n_d_ _s_e_c_u_r_e_ _p_l_a_c_e_ _t_o_ _l_i_v_e_ _i_n_.'], ['I_n_ _s_h_o_r_t_,_ _m_y_ _p_r_o_v_e_n_ _a_b_i_l_i_t_i_e_s_ _w_o_u_l_d_ _m_a_k_e_ _m_e_ _a_ _p_e_r_f_e_c_t_ _f_i_t_.'], ['M_y_ _a_m_b_i_t_i_o_n_ _t_o_ _f_u_r_t_h_e_r_ _d_e_v_e_l_o_p_ _m_y_s_e_l_f_ _a_n_d_ _m_y_ _t_h_i_r_s_t_ _f_o_r_ _e_m_p_l_o_y_i_n_g_ _t_h_e_ _t_h_i_n_g_s_ _I_ _l_e_a_r_n_ _i_n_ _h_e_l_p_i_n_g_ _o_t_h_e_r_s_ _e_s_p_e_c_i_a_l_l_y_ _S_y_r_i_a_n_s_ _i_n_ _t_i_m_e_s_ _o_f_ _w_a_r_ _a_n_d_ _l_a_t_e_r_ _o_n_ _i_n_ _r_e_b_u_i_l_d_i_n_g_ _S_y_r_i_a_ _i_s_ _t_h_e_ _s_t_r_o_n_g_e_s_t_ _m_o_t_i_v_a_t_i_o_n_ _t_o_ _k_e_e_p_ _m_e_ _w_o_r_k_i_n_g_ _r_e_l_e_n_t_l_e_s_s_l_y_.'], ['T_h_i_s_ _m_a_k_e_s_ _m_e_ _m_e_e_t_ _t_h_e_ _s_t_a_n_d_a_r_d_s_ _o_f_ _y_o_u_r_ _p_r_e_s_t_i_g_i_o_u_s_ _i_n_s_t_i_t_u_t_i_o_n_.']]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}