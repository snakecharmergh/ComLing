{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CompLingSpellChecking hw3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPrqyAjE2U0zDTCCCbHjZpr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snakecharmergh/ComLing/blob/master/CompLingSpellChecking_hw3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ddnxHwVMe3T",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Homework 3** \n",
        "\n",
        "Implement the Symspell algorithm. It's similar to Norwig's algorithm, but simpler and faster. There is only one operation applied to words in the dictionary - delete character (1-n). To find a correction from a word, the characters are also removed and compared to those stored in the dictionary. Assess the quality of the resulting algorithm with the same three metrics.\n",
        "\n",
        "Add a trigram model to the resulting algorithm correction (Symspell) and check if it improves the quality. The trigram model should be inserted where you select one of several candidates for the correction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TBQ9RfgMzWY",
        "colab_type": "code",
        "outputId": "0e3ffb24-17ba-4a17-9850-0c9c54dd6504",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/correct_sents.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-15 12:21:51--  https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/correct_sents.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 120672 (118K) [text/plain]\n",
            "Saving to: ‘correct_sents.txt.1’\n",
            "\n",
            "\rcorrect_sents.txt.1   0%[                    ]       0  --.-KB/s               \rcorrect_sents.txt.1 100%[===================>] 117.84K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-04-15 12:21:52 (3.06 MB/s) - ‘correct_sents.txt.1’ saved [120672/120672]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DHTZpx2MdTQ",
        "colab_type": "code",
        "outputId": "3aaa6e22-9c88-4859-feed-6bdb6c49ea7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/sents_with_mistakes.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-15 12:21:44--  https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/sents_with_mistakes.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 123167 (120K) [text/plain]\n",
            "Saving to: ‘sents_with_mistakes.txt.1’\n",
            "\n",
            "\r          sents_wit   0%[                    ]       0  --.-KB/s               \rsents_with_mistakes 100%[===================>] 120.28K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-04-15 12:21:44 (3.19 MB/s) - ‘sents_with_mistakes.txt.1’ saved [123167/123167]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYiLNljfNDIJ",
        "colab_type": "code",
        "outputId": "ef92ab4f-047e-4fbc-98c9-d4dcb2814c5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "\n",
        "\n",
        "!wget https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-15 12:21:59--  https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/87156914/0b363e00-0126-11e9-9e3c-e8c235463bd6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200415%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200415T122159Z&X-Amz-Expires=300&X-Amz-Signature=78752063af720b4a9bdce4bd5944cfd443f1066d6a2af3bab1abea12f879a2b5&X-Amz-SignedHeaders=host&actor_id=0&repo_id=87156914&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2020-04-15 12:21:59--  https://github-production-release-asset-2e65be.s3.amazonaws.com/87156914/0b363e00-0126-11e9-9e3c-e8c235463bd6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200415%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200415T122159Z&X-Amz-Expires=300&X-Amz-Signature=78752063af720b4a9bdce4bd5944cfd443f1066d6a2af3bab1abea12f879a2b5&X-Amz-SignedHeaders=host&actor_id=0&repo_id=87156914&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.138.131\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.138.131|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 527373240 (503M) [application/octet-stream]\n",
            "Saving to: ‘lenta-ru-news.csv.gz.1’\n",
            "\n",
            "lenta-ru-news.csv.g 100%[===================>] 502.94M  71.3MB/s    in 6.0s    \n",
            "\n",
            "2020-04-15 12:22:05 (83.1 MB/s) - ‘lenta-ru-news.csv.gz.1’ saved [527373240/527373240]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTNRP83ENKsi",
        "colab_type": "code",
        "outputId": "4e208828-74d8-426a-b6e5-e8c301f7b96e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "!pip install symspellpy\n",
        "import os, re\n",
        "import gzip\n",
        "import csv\n",
        "import pkg_resources\n",
        "from collections import Counter, defaultdict\n",
        "from pprint import pprint\n",
        "from nltk import sent_tokenize\n",
        "from symspellpy import SymSpell, Verbosity\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from string import punctuation\n",
        "punctuation += \"«»—…“”\"\n",
        "punct = set(punctuation)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: symspellpy in /usr/local/lib/python3.6/dist-packages (6.5.2)\n",
            "Requirement already satisfied: numpy>=1.13.1 in /usr/local/lib/python3.6/dist-packages (from symspellpy) (1.18.2)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pmv2l_ayvBY",
        "colab_type": "text"
      },
      "source": [
        "We take data, which is a set of sentences (right - wrong) to check for misspelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jShi1h2tNlVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bad = open('sents_with_mistakes.txt', encoding='utf8').read().splitlines()\n",
        "true = open('correct_sents.txt', encoding='utf8').read().splitlines()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FxOfxwcUVWA",
        "colab_type": "code",
        "outputId": "128ce04b-d18f-4513-fbe7-368ec78bb83f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(bad[5])\n",
        "print(true[5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Нащщот Чавеса разве что не соглашусь.\n",
            "Насчет Чавеса разве что не соглашусь\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJWKxKtxzpOU",
        "colab_type": "text"
      },
      "source": [
        "We define a function that will match and align both correct and wrong words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7nwN1ctS4kf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def align_words(sent_1, sent_2):\n",
        "    tokens_1 = sent_1.lower().split()\n",
        "    tokens_2 = sent_2.lower().split()\n",
        "    \n",
        "    tokens_1 = [re.sub('(^\\W+|\\W+$)', '', token) for token in tokens_1 if (set(token)-punct)]\n",
        "    tokens_2 = [re.sub('(^\\W+|\\W+$)', '', token) for token in tokens_2 if (set(token)-punct)]\n",
        "    \n",
        "    return list(zip(tokens_1, tokens_2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqAp_gHPS_UN",
        "colab_type": "code",
        "outputId": "cc58d441-6a0c-4015-9a72-c5da43f79db6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "pprint(align_words(true[3], bad[3]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('получатся', 'полчатся'),\n",
            " ('вот', 'вот'),\n",
            " ('такие', 'такие'),\n",
            " ('язычки', 'язычки')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o31Hmvd_1xjz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48wDj_W_0FSg",
        "colab_type": "text"
      },
      "source": [
        "Take out only the wrong variants and at the same time calculate the error rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YpDPevHwzvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mistakes = []\n",
        "total = 0\n",
        "for i in range(len(true)):\n",
        "    word_pairs = align_words(true[i], bad[i])\n",
        "    for pair in word_pairs:\n",
        "        if pair[0] != pair[1]:\n",
        "            mistakes.append(pair)\n",
        "        total += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83kh8rmDw12C",
        "colab_type": "code",
        "outputId": "0aa2b4e0-6091-4265-d099-a24a40b05373",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Доля ошибок Error rate - ', len(mistakes)/total )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля ошибок Error rate -  0.13016983016983016\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3jzex0T0X8N",
        "colab_type": "text"
      },
      "source": [
        "Since the error rate is rather low, we need a simple classifier that will select the incorrect words to edit them later. Thus, we compile a dictionary of correct words and then compare the wrong words to the correct words in it. \n",
        "In order to compile a dictionary, we take some body of texts (such as News texts)that have been edited."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59z0elMRNRy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = open('corpus_5000.txt', 'w')\n",
        "with gzip.open('lenta-ru-news.csv.gz', 'rt') as archive:\n",
        "    reader = csv.reader(archive, delimiter=',', quotechar='\"')\n",
        "    for i, line in enumerate(reader):\n",
        "        if i < 5000: \n",
        "            corpus.write(line[2].replace('\\xa0', ' ') + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tziMPWM5RTx4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(text):\n",
        "    \n",
        "    normalized_text = [(word.strip(punctuation)) for word \\\n",
        "                                                            in text.lower().split()]\n",
        "    normalized_text = [word for word in normalized_text if word]\n",
        "    return normalized_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezEphmb5SCxF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = []\n",
        "for text in open('corpus_5000.txt').read().splitlines()[:12000]:\n",
        "    sents = sent_tokenize(text)\n",
        "    norm_sents = [normalize(sent) for sent in sents]\n",
        "    corpus += norm_sents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QBAKK2g3Ngu",
        "colab_type": "text"
      },
      "source": [
        "We predict the error by simply looking into the dictionary. If a word is not in the dictionary, it is incorrect.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiOuptnS561u",
        "colab_type": "text"
      },
      "source": [
        "**Fixing the misspelling in the wrong words by implementing the Symspell algorithm:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g99xG8rj69t2",
        "colab_type": "text"
      },
      "source": [
        "We generate possible fixes and select those in the dictionary that we create:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyWiJB22JjUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "WORDS = Counter()\n",
        "for sent in corpus:\n",
        "    WORDS.update(sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fJH__ltNLPD",
        "colab_type": "code",
        "outputId": "3b3a893b-dde6-42eb-ac26-7c13865c84af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"модель\" in WORDS"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mqoibAgNXY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# фунцкия расчета вероятности слова  function to calculate word probability \n",
        "N = sum(WORDS.values())\n",
        "def P(word, N=N): \n",
        "    \"Вычисляем вероятность слова We calculate the probability of the word\"\n",
        "    return WORDS[word] / N"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qQZUAWCNxRC",
        "colab_type": "code",
        "outputId": "d248c41f-57d1-4454-a855-e6effbd02200",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "P('модель')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00011367214452731144"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YZOA_ZdNyni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def deletes(word):\n",
        "    letters    = 'йцукенгшщзхъфывапролджэячсмитьбюё'\n",
        "    splits     = [(word[:i], word[i:])     for i in range(len(word) + 1)]\n",
        "    deletes1    = [L + R[1:]               for L, R in splits if R]\n",
        "    splits2     = [(word[:i], word[i:])    for i in range(len(deletes1))]\n",
        "    deletes2    = [L + R[2:]               for L, R in splits2 if R]\n",
        "    deletes = deletes1 + deletes2\n",
        "    return set(deletes)\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTyHu6GwDF0z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "global_worddict = {}\n",
        "for i in unigrams.keys():\n",
        "  for j in deletes(i):\n",
        "    global_worddict[j] = i"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYt0bNAhGEh9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def correction(input_word):\n",
        "  candidates_list = []\n",
        "  candidates_dict = {}\n",
        "  strongest_candidate = input_word\n",
        "  if input_word in unigrams:\n",
        "    return input_word\n",
        "  for i in deletes(input_word):\n",
        "    if i in global_worddict:\n",
        "      candidates_dict[unigrams[global_worddict[i]]] = global_worddict[i]\n",
        "      strongest_candidate = max(candidates_dict.keys())\n",
        "      strongest_candidate = candidates_dict[strongest_candidate]\n",
        "  return strongest_candidate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBBSEtCg5j7t",
        "colab_type": "code",
        "outputId": "0fb923e2-174c-414c-a7a8-c568d778e735",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "%%time\n",
        "deletes('сонце')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 39 µs, sys: 1e+03 ns, total: 40 µs\n",
            "Wall time: 44.6 µs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'нце', 'онце', 'снце', 'сое', 'сон', 'соне', 'сонц', 'соце', 'сце'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cif1SZAj01q",
        "colab_type": "code",
        "outputId": "bfe98043-3c04-4902-cf01-6e628f44ebdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correction('сонце')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'конце'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPxPk1sxJDYX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word = 'модель'\n",
        "splits = [(word[:i], word[i:])    for i in range(len(word) + 1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x58SkvdlJIm1",
        "colab_type": "code",
        "outputId": "60301a68-87bb-4a76-ce39-8ebe763fe509",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "splits[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('', 'модель'),\n",
              " ('м', 'одель'),\n",
              " ('мо', 'дель'),\n",
              " ('мод', 'ель'),\n",
              " ('моде', 'ль'),\n",
              " ('модел', 'ь'),\n",
              " ('модель', '')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFQI05-78sLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "deletes = [L + R[1:] for L, R in splits if R]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKCpYXz-8yW7",
        "colab_type": "code",
        "outputId": "2897e213-c096-4995-ce9d-cc4bf347f14c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "deletes[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['одель', 'мдель', 'моель', 'модль', 'модеь', 'модел']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77bP8a_8uBv7",
        "colab_type": "text"
      },
      "source": [
        "We  use three metrics for evaluation:\n",
        "\n",
        "1) percentage of correct words;\n",
        "\n",
        "2) percentage of corrected errors\n",
        "\n",
        "3) percentage of correct words corrected incorrectly\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6sgXGhBj80L",
        "colab_type": "code",
        "outputId": "0773a79d-ea63-4588-8a8a-5fccd399af7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "total_mistaken = 0\n",
        "mistaken_fixed = 0\n",
        "\n",
        "total_correct = 0\n",
        "correct_broken = 0\n",
        "\n",
        "cashed = {}\n",
        "for i in range(len(true)):\n",
        "    word_pairs = align_words(true[i], bad[i])\n",
        "    for pair in word_pairs:\n",
        "        predicted = cashed.get(pair[1], correction(pair[1]))\n",
        "        cashed[pair[0]] = predicted\n",
        "        if predicted == pair[0]:\n",
        "            correct += 1\n",
        "        total += 1\n",
        "        \n",
        "        if pair[0] == pair[1]:\n",
        "            total_correct += 1\n",
        "            if pair[0] !=  predicted:\n",
        "                correct_broken += 1\n",
        "        else:\n",
        "            total_mistaken += 1\n",
        "            if pair[0] == predicted:\n",
        "                mistaken_fixed += 1\n",
        "        \n",
        "    if not i % 100:\n",
        "        print(i)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fbqzr4iyj_45",
        "colab_type": "code",
        "outputId": "2d91bf85-9507-4dfa-eff1-d487ebc65300",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print(correct/total)\n",
        "print(mistaken_fixed/total_mistaken)\n",
        "print(correct_broken/total_correct)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6593406593406593\n",
            "0.363008442056792\n",
            "0.2963133111289767\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuxRmlbrsICo",
        "colab_type": "code",
        "outputId": "16c7703e-2c4d-4618-ae34-88ea483c66f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "%%time\n",
        "deletes('солнце')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 24 µs, sys: 1e+03 ns, total: 25 µs\n",
            "Wall time: 29.1 µs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'лнце',\n",
              " 'олнце',\n",
              " 'слнце',\n",
              " 'снце',\n",
              " 'соле',\n",
              " 'солн',\n",
              " 'солне',\n",
              " 'солнц',\n",
              " 'солце',\n",
              " 'сонце',\n",
              " 'соце'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpF44i-bsZ-M",
        "colab_type": "code",
        "outputId": "93aa5d28-a47f-439b-b3a0-bf292b7315de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        }
      },
      "source": [
        "%%time\n",
        "deletes('насмехатьсяаававттававаываываы')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 66 µs, sys: 2 µs, total: 68 µs\n",
            "Wall time: 70.8 µs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'асмехатьсяаававттававаываываы',\n",
              " 'наехатьсяаававттававаываываы',\n",
              " 'намехатьсяаававттававаываываы',\n",
              " 'насехатьсяаававттававаываываы',\n",
              " 'насматьсяаававттававаываываы',\n",
              " 'насмеатьсяаававттававаываываы',\n",
              " 'насметьсяаававттававаываываы',\n",
              " 'насмехасяаававттававаываываы',\n",
              " 'насмехатсяаававттававаываываы',\n",
              " 'насмехатьаававттававаываываы',\n",
              " 'насмехатьсаававттававаываываы',\n",
              " 'насмехатьсававттававаываываы',\n",
              " 'насмехатьсяааавттававаываываы',\n",
              " 'насмехатьсяаававававаываываы',\n",
              " 'насмехатьсяаававтававаываываы',\n",
              " 'насмехатьсяаававтваваываываы',\n",
              " 'насмехатьсяаававттааваываываы',\n",
              " 'насмехатьсяаававттавааываываы',\n",
              " 'насмехатьсяаававттававааываы',\n",
              " 'насмехатьсяаававттавававаываы',\n",
              " 'насмехатьсяаававттававаыаываы',\n",
              " 'насмехатьсяаававттававаывааы',\n",
              " 'насмехатьсяаававттававаываваы',\n",
              " 'насмехатьсяаававттававаываыаы',\n",
              " 'насмехатьсяаававттававаываыв',\n",
              " 'насмехатьсяаававттававаываыва',\n",
              " 'насмехатьсяаававттававаываывы',\n",
              " 'насмехатьсяаававттававаываыы',\n",
              " 'насмехатьсяаававттававаывваы',\n",
              " 'насмехатьсяаававттававаывываы',\n",
              " 'насмехатьсяаававттававаыываы',\n",
              " 'насмехатьсяаававттававваываы',\n",
              " 'насмехатьсяаававттававываываы',\n",
              " 'насмехатьсяаававттаваываываы',\n",
              " 'насмехатьсяаававттавваываываы',\n",
              " 'насмехатьсяаававттваваываываы',\n",
              " 'насмехатьсяааватававаываываы',\n",
              " 'насмехатьсяааваттававаываываы',\n",
              " 'насмехатьсяааввттававаываываы',\n",
              " 'насмехатьсяаавттававаываываы',\n",
              " 'насмехатьсяававттававаываываы',\n",
              " 'насмехатьсявавттававаываываы',\n",
              " 'насмехатьяаававттававаываываы',\n",
              " 'насмехатяаававттававаываываы',\n",
              " 'насмехаьсяаававттававаываываы',\n",
              " 'насмехтьсяаававттававаываываы',\n",
              " 'насмехьсяаававттававаываываы',\n",
              " 'насмхатьсяаававттававаываываы',\n",
              " 'насхатьсяаававттававаываываы',\n",
              " 'нмехатьсяаававттававаываываы',\n",
              " 'нсмехатьсяаававттававаываываы',\n",
              " 'смехатьсяаававттававаываываы'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-a83IlFmXzv",
        "colab_type": "text"
      },
      "source": [
        "**Assessment:** Symspell works much faster than  Norwig's algorithm for both short and long words.However, the percentage of correct broken has increased. Also the percentage of mistakes fixed has decreased. Hence the percentage of total correct words has considerably decreased.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ag78QMAXpem",
        "colab_type": "text"
      },
      "source": [
        "To improve the quality of fixes, we can try to consider the context. Language models can help us to do this. We can teach the language model on our news corpus and then blend each distance for probability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9NjNLqKOV6d",
        "colab_type": "text"
      },
      "source": [
        "**Trigram Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXN5nTRCOcdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_news = [['<start>', '<start>'] + sent + ['<end>'] for sent in corpus]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGVatU_jOjBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = []\n",
        "for text in open('corpus_5000.txt').read().splitlines():\n",
        "    sents = sent_tokenize(text)\n",
        "    norm_sents = [normalize(sent) for sent in sents]\n",
        "    corpus += norm_sents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRUQMgBVOmul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ngrammer(tokens, n=2):\n",
        "    ngrams = []\n",
        "    for i in range(0,len(tokens)-n+1):\n",
        "        ngrams.append(' '.join(tokens[i:i+n]))\n",
        "    return ngrams"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkTseCM-Op-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unigrams = Counter()\n",
        "bigrams = Counter()\n",
        "trigrams = Counter()\n",
        "\n",
        "for sentence in corpus_news:\n",
        "    unigrams.update(sentence)\n",
        "    bigrams.update(ngrammer(sentence))\n",
        "    trigrams.update(ngrammer(sentence, n=3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLEbw2NGOt1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trigram_in_pro(input_words):\n",
        "  candidates_list = []\n",
        "  candidates_dict = {}\n",
        "  input_word = str(input_words.split()[-1])\n",
        "  strongest_candidate = input_word\n",
        "  if input_word in unigrams:\n",
        "    return input_word\n",
        "  for i in deletes(input_word):\n",
        "    if i in glob_dict:\n",
        "      one_word_prob = unigrams[glob_dict[i]]/len(unigrams)\n",
        "      bigram = \" \".join(input_words.split()[:-1]) \n",
        "      if unigrams[input_words.split()[0]]:\n",
        "        bigram_prob = bigrams[bigram]/unigrams[input_words.split()[0]]\n",
        "        trigram = bigram + \" \" + glob_dict[i]\n",
        "      if bigrams[bigram]:\n",
        "        trigram_prob = trigrams[trigram]/bigrams[bigram]\n",
        "        prob_with_context = one_word_prob*(1 + trigram_prob/bigram_prob)\n",
        "      else:\n",
        "         prob_with_context = one_word_prob\n",
        "      candidates_dict[unigrams[glob_dict[i]]] = glob_dict[i]\n",
        "      strongest_candidate = max(candidates_dict.keys())\n",
        "      strongest_candidate = candidates_dict[strongest_candidate]\n",
        "  return strongest_candidate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5zUQ5k-OxLU",
        "colab_type": "code",
        "outputId": "90fec8a1-2b40-462b-acf3-44b6406c28b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trigram_in_pro(\"проходит со временим\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'временами'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvSm5VwyO1Zd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "total_mistaken = 0\n",
        "mistaken_fixed = 0\n",
        "\n",
        "total_correct = 0\n",
        "correct_broken = 0\n",
        "\n",
        "cashed = {}\n",
        "for i in range(len(true)):\n",
        "  for j in range(len(true[i].split())):\n",
        "    word_pairs = align_words(true[i], bad[i])\n",
        "    if j == 0:\n",
        "      r_bigram = \"<start> <start> \"\n",
        "    elif j == len(true[i].split()):\n",
        "      r_bigram = true[i][j-1] + \" \" + true[i][j] + \" \"\n",
        "    else:\n",
        "      r_bigram = true[i][j-2] + \" \" + true[i][j-1] + \" \"\n",
        "    for pair in word_pairs:\n",
        "      predicted = cashed.get(pair[1], trigram_in_pro(r_bigram + pair[1]))\n",
        "      cashed[pair[0]] = predicted\n",
        "      if predicted == pair[0]:\n",
        "          correct += 1\n",
        "      total += 1\n",
        "      \n",
        "      if pair[0] == pair[1]:\n",
        "          total_correct += 1\n",
        "          if pair[0] !=  predicted:\n",
        "              correct_broken += 1\n",
        "      else:\n",
        "          total_mistaken += 1\n",
        "          if pair[0] == predicted:\n",
        "              mistaken_fixed += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKr2JUATO5w8",
        "colab_type": "code",
        "outputId": "f0fa93e5-3436-4162-e965-4bc2e305b5e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print(correct/total)\n",
        "print(mistaken_fixed/total_mistaken)\n",
        "print(correct_broken/total_correct)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6663466885575828\n",
            "0.34051211419270017\n",
            "0.2951235943410893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyzg3jVanQyi",
        "colab_type": "text"
      },
      "source": [
        "** Assessment**\n",
        "The percentage of correct broken is almost the same. While the percentage of mistakes fixed has decreased.The percentage of total correct words has very slightly increased.  "
      ]
    }
  ]
}